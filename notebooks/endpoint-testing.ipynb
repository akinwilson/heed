{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing TensorRT endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent 100 queries in 4.238741397857666 seconds\n",
      "QPS: 23.59\n",
      "Avg inference time: 1.4751449227333069\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import base64\n",
    "import numpy as np\n",
    "import scipy.io  as io\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "path = \"/home/akinwilson/Code/pytorch/dataset/keywords/yes/yes.f5626af6_nohash_2.wav\"\n",
    "train_df_path = \"/home/akinwilson/Code/pytorch/dataset/keywords/train.csv\"\n",
    "df = pd.read_csv(train_df_path).sample(n=100)\n",
    "\n",
    "def encode_wav(path):\n",
    "    _, wav = io.wavfile.read(path)\n",
    "    wav\n",
    "    s = base64.b64encode(wav)\n",
    "    return s \n",
    "\n",
    "\n",
    "data_list = [{'base64str': encode_wav(path).decode('utf-8')} for path in df.wav_path]\n",
    "\n",
    "\n",
    "def send_request(data):\n",
    "    url = 'http://0.0.0.0:8080/api/v1/predict'\n",
    "    x = requests.post(url, json = data)\n",
    "    return x.json()\n",
    "\n",
    "\n",
    "# x = send_request(data_list[0])\n",
    "# status  = x['error']\n",
    "# response = x['result']\n",
    "\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time \n",
    "pool = mp.Pool(processes=40)\n",
    "s = time.time()\n",
    "results = pool.map(send_request, data_list)\n",
    "f = time.time()\n",
    "print(f\"Sent {len(data_list)} queries in {f-s} seconds\")\n",
    "print(f\"QPS: {(len(data_list) / (f-s) ):.2f}\")\n",
    "# print \"\\nTotal took \" + str(millis() - start_time) + \" ms\\n\"\n",
    "# for result in results:\n",
    "inf_times = [result['result']['inference_time'] for result in results] \n",
    "avg_inf = sum(inf_times) / len(inf_times)\n",
    "print(f\"Avg inference time: {avg_inf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/akinwilson/Code/pytorch/dataset/data/000a5b70-dfe9-4bf5-9199-85feb935bfdb.wav\"\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import base64 \n",
    "\n",
    "samplerate, data = wavfile.read(path)\n",
    "\n",
    "\n",
    "txt = base64.b64encode(data)\n",
    "\n",
    "# with open(\"bas64.example\", \"wb\") as file:\n",
    "#     file.write(txt)\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "decoded_wav = base64.decodebytes(txt)\n",
    "x = np.frombuffer(decoded_wav, dtype=np.int16)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing onnx runtime\n",
    "\n",
    " Issue with CUDA as exection provider. \n",
    "\n",
    " see: \n",
    " \n",
    "    https://stackoverflow.com/questions/70014477/onnxruntime-not-using-cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session.get_providers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx \n",
    "\n",
    "# path= \"/home/akinwilson/Code/pytorch/output/model/DeepSpeech/2022_09_12_11.22.09_AM/export/DeepSpeech.onnx\"\n",
    "\n",
    "# p = \"/home/akinwilson/Code/pytorch/output/model/DeepSpeech/2022_09_12_11.22.09_AM/inference/DeepSpeech.pt\"\n",
    "\n",
    "import onnxruntime\n",
    "import torch \n",
    "import time \n",
    "import logging \n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "x = torch.randn(1, 1, 48000, device='cpu')\n",
    "s = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime as ort\n",
    "# ort.get_all_providers()\n",
    "# ort.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime\n",
    "# import torch \n",
    "# import time \n",
    "# onnxruntime.get_providers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = \"/home/akinwilson/Code/pytorch/output/model/DeepSpeech/2022_09_12_11.22.09_AM/inference/DeepSpeech.pt\"\n",
    "# import torch \n",
    "# import time \n",
    "# # model = torch.load(p)\n",
    "# s= time.time()\n",
    "# model.forward(x)\n",
    "# f = time.time()\n",
    "# print(f\"Serving python: {(f-s)* 1e3:.5f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-T3BHxh3q",
   "language": "python",
   "name": "pytorch-t3bhxh3q"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
