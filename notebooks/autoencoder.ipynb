{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6112835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import librosa\n",
    "import warnings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\" # set vis gpus \n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import wwv.config  as cfg \n",
    "# from wwv.meta import params as params \n",
    "from wwv.data import AudioDataModule\n",
    "\n",
    "torch.cuda.is_available()\n",
    "cfg_fitting = cfg.Fitting()\n",
    "cfg_feature = cfg.Feature()\n",
    "cfg_signal = cfg.Signal()\n",
    "cfg_model = cfg.HTSwin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12fa6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = cfg.DataPath(\"/home/akinwilson/Code/HTS\", cfg_model.model_name, cfg_model.model_dir)\n",
    "data_module = AudioDataModule(data_path.root_data_dir, cfg_model=cfg_model, cfg_feature=cfg_feature, cfg_fitting=cfg_fitting)\n",
    "                              \n",
    "train_loader =  data_module.train_dataloader()\n",
    "val_loader =  data_module.val_dataloader()\n",
    "test_loader =  data_module.test_dataloader()\n",
    "\n",
    "x = next(iter(train_loader))['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b919208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ffdb0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before flat for fully connect:\n",
      "torch.Size([32, 64, 28])\n",
      "torch.Size([32, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 31424])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNNAE(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=1024, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_channel = n_channel\n",
    "\n",
    "\n",
    "        # encoder layers \n",
    "        self.e_conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.e_bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.e_pool1 = nn.MaxPool1d(4, return_indices=True)\n",
    "        self.e_conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.e_bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.e_pool2 = nn.MaxPool1d(4, return_indices=True)\n",
    "        self.e_conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        # \n",
    "        self.e_bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.e_pool3 = nn.MaxPool1d(4, return_indices=True)\n",
    "        self.e_conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "#######################################################################################\n",
    "        self.e_bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.e_pool4 = nn.MaxPool1d(2, return_indices=True)\n",
    "        self.e_fc4 = nn.Linear(2 * n_channel * 28, n_output)\n",
    "#######################################################################################\n",
    "        # decoder layers \n",
    "        self.d_fc4 = nn.Linear(n_output, 2 * n_channel * 28)\n",
    "        self.d_pool4 = nn.MaxUnpool1d(2)\n",
    "        self.d_bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "#######################################################################################\n",
    "\n",
    "        self.d_conv4 = nn.ConvTranspose1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.d_pool3 = nn.MaxUnpool1d(4)\n",
    "        self.d_bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "#######################################################################################\n",
    "        self.d_conv3 = nn.ConvTranspose1d(2 * n_channel, n_channel, kernel_size=3)\n",
    "        self.d_pool2 = nn.MaxUnpool1d(4)\n",
    "        self.d_bn2 = nn.BatchNorm1d(n_channel)\n",
    "\n",
    "\n",
    "        self.d_conv2 = nn.ConvTranspose1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.d_pool1 = nn.MaxUnpool1d(4)\n",
    "        self.d_bn1 = nn.BatchNorm1d(n_channel)\n",
    "\n",
    "        self.d_conv1 = nn.ConvTranspose1d(n_channel, n_input, kernel_size=80, stride=stride)\n",
    "    \n",
    "\n",
    "\n",
    "    def encode_forward(self, x):\n",
    "        x = self.e_conv1(x)\n",
    "        x = F.relu(self.e_bn1(x))\n",
    "        x, idx1 = self.e_pool1(x)\n",
    "        x = self.e_conv2(x)\n",
    "        x = F.relu(self.e_bn2(x))\n",
    "        x, idx2 = self.e_pool2(x)\n",
    "        x = self.e_conv3(x)\n",
    "        x = F.relu(self.e_bn3(x))\n",
    "        x, idx3  = self.e_pool3(x)\n",
    "        x = self.e_conv4(x)\n",
    "        x = F.relu(self.e_bn4(x))\n",
    "        print(\"before flat for fully connect:\")\n",
    "        print(x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.e_fc4(x)\n",
    "        return idx1, idx2, idx3, x\n",
    "\n",
    "\n",
    "    def decode_forward(self, idx1, idx2, idx3, x):\n",
    "\n",
    "        x = self.d_fc4(x)\n",
    "        x = x.view(x.shape[0], 2 * self.n_channel,  28)\n",
    "        x = F.relu(self.d_bn4(x))\n",
    "        x = self.d_conv4(x)\n",
    "        x = self.d_pool3(x, idx3)\n",
    "\n",
    "        x = F.relu(self.d_bn3(x))\n",
    "\n",
    "        x = self.d_conv3(x)\n",
    "        idx2 = idx2[:,:,:122] # due to padding\n",
    "\n",
    "        x = self.d_pool2(x, idx2)\n",
    "\n",
    "        x = F.relu(self.d_bn2(x))\n",
    "        x = self.d_conv2(x)\n",
    "        idx1 = idx1[:,:,:490] # due to padding\n",
    "        x = self.d_pool1(x, idx1)\n",
    "        x = F.relu(self.d_bn1(x))\n",
    "        x = self.d_conv1(x)\n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        idx1, idx2, idx3, encoded_x = self.encode_forward(x)\n",
    "        print(encoded_x.shape)\n",
    "        decoded_x = self.decode_forward(idx1, idx2, idx3,encoded_x)\n",
    "        return decoded_x\n",
    "\n",
    "\n",
    "CNNAE()(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d050d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7456f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7aac0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HTS-Audio-Transformer-BsLXlc73",
   "language": "python",
   "name": "hts-audio-transformer-bslxlc73"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
