{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wwv.config import Config \n",
    "MODEL_DIR = \"/home/akinwilson/Code/pytorch/output/model\"\n",
    "DATA_DIR = \"/home/akinwilson/Code/pytorch/dataset/keywords\"\n",
    "LR_RANGE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5][1]\n",
    "BATCH_SIZE_RANGE = [1,2,32, 64, 128, 256][2]\n",
    "EPOCH_RANGE = [1, 10, 30, 50, 100, 1000][1]\n",
    "ES_PATIENCE_RANGE = [1, 10, 20, 100, 200][2]\n",
    "MODELS = [\"VecM5\", \"Resnet2vec1D\",\"SpecResnet2D\", \"HSTAT\", \"DeepSpeech\", \"ResNet\"][-3]\n",
    "AUDIO_FEATURE_OPT = [\"spectrogram\", \"mfcc\", \"pcm\"][0]\n",
    "PRETRAINED_MODEL_NAME_OR_PATH = \"facebook/wav2vec2-base-960h\"\n",
    "AUGS = False\n",
    "params = {\n",
    "    \"audio_duration\":3,\n",
    "    \"sample_rate\":16000,\n",
    "    \"model_name\": MODELS,\n",
    "    \"verbose\": False,\n",
    "    \"path\": {\n",
    "        \"model_dir\": MODEL_DIR,\n",
    "        \"data_dir\": DATA_DIR,\n",
    "        \"pretrained_name_or_path\": PRETRAINED_MODEL_NAME_OR_PATH\n",
    "        },\n",
    "    \"fit_param\": {\"init_lr\":LR_RANGE, \"weight_decay\":0.0001, \"max_epochs\":EPOCH_RANGE, \"gamma\": 0.1,\"es_patience\":ES_PATIENCE_RANGE}, \n",
    "    \"data_param\":{\"train_batch_size\": BATCH_SIZE_RANGE, \"val_batch_size\": BATCH_SIZE_RANGE,\"test_batch_size\": BATCH_SIZE_RANGE}, \n",
    "    \"audio_feature\": AUDIO_FEATURE_OPT,\n",
    "    \"audio_feature_param\": { \"mfcc\":{\"sr\":16000,\"n_mfcc\":20,\"norm\": 'ortho',\"verbose\":True,\"ref\":1.0,\"amin\":1e-10,\"top_db\":80.0,\"hop_length\":512,},\n",
    "                            \"spectrogram\":{\"sr\":16000, \"n_fft\":2048, \"win_length\":None,\"n_mels\":128,\"hop_length\":512,\"window\":'hann',\"center\":True,\"pad_mode\":'reflect',\"power\":2.0,\"htk\":False,\"fmin\":0.0,\"fmax\":None,\"norm\":1,\"trainable_mel\":False,\"trainable_STFT\":False,\"verbose\": True },\n",
    "                            \"pcm\": {}},\n",
    "    \"augmentation\":{'Gain': AUGS, 'PitchShift': AUGS, 'Shift': AUGS},\n",
    "    \"augmentation_param\":{\"Gain\": {  \"min_gain_in_db\":-18.0,\"max_gain_in_db\":  6.0,\"mode\":'per_example',\"p\":1,\"p_mode\":'per_example'},\n",
    "                        \"PitchShift\": {\"min_transpose_semitones\": -4.0, \"max_transpose_semitones\": 4.0,\"mode\":'per_example',\"p\":1,\"p_mode\":'per_example',\"sample_rate\":16000,\"target_rate\": None,\"output_type\": None,},\n",
    "                        \"Shift\":{ \"min_shift\":-0.5,\"max_shift\": 0.5,\"shift_unit\":'fraction',\"rollover\": True,\"mode\":'per_example',\"p\":1,\"p_mode\": 'per_example',\"sample_rate\": 16000,\"target_rate\":None,\"output_type\":None}},\n",
    "    }\n",
    "cfg = Config(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akinwilson/.local/share/virtualenvs/pytorch-T3BHxh3q/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from itertools import repeat\n",
    "import collections.abc\n",
    "import math\n",
    "import warnings\n",
    "from torch.nn.init import _calculate_fan_in_and_fan_out\n",
    "# from PyTorch internals\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, collections.abc.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "to_1tuple = _ntuple(1)\n",
    "to_2tuple = _ntuple(2)\n",
    "to_3tuple = _ntuple(3)\n",
    "to_4tuple = _ntuple(4)\n",
    "to_ntuple = _ntuple\n",
    "\n",
    "\n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "    random_tensor.floor_()  # binarize\n",
    "    output = x.div(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" 2D Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, norm_layer=None, flatten=True, patch_stride = 16):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        patch_stride = to_2tuple(patch_stride)\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_stride = patch_stride\n",
    "        self.grid_size = (img_size[0] // patch_stride[0], img_size[1] // patch_stride[1])\n",
    "        self.num_patches = self.grid_size[0] * self.grid_size[1]\n",
    "        self.flatten = flatten\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        padding = ((patch_size[0] - patch_stride[0]) // 2, (patch_size[1] - patch_stride[1]) // 2)\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_stride, padding=padding)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x)\n",
    "        if self.flatten:\n",
    "            x = x.flatten(2).transpose(1, 2)  # BCHW -> BNC\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    \"\"\" MLP as used in Vision Transformer, MLP-Mixer and related networks\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
    "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    def norm_cdf(x):\n",
    "        # Computes standard normal cumulative distribution function\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",\n",
    "                      stacklevel=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Values are generated by using a truncated uniform distribution and\n",
    "        # then using the inverse CDF for the normal distribution.\n",
    "        # Get upper and lower cdf values\n",
    "        l = norm_cdf((a - mean) / std)\n",
    "        u = norm_cdf((b - mean) / std)\n",
    "\n",
    "        # Uniformly fill tensor with values from [l, u], then translate to\n",
    "        # [2l-1, 2u-1].\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "\n",
    "        # Use inverse cdf transform for normal distribution to get truncated\n",
    "        # standard normal\n",
    "        tensor.erfinv_()\n",
    "\n",
    "        # Transform to proper mean, std\n",
    "        tensor.mul_(std * math.sqrt(2.))\n",
    "        tensor.add_(mean)\n",
    "\n",
    "        # Clamp to ensure it's in the proper range\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    # type: (Tensor, float, float, float, float) -> Tensor\n",
    "    r\"\"\"Fills the input Tensor with values drawn from a truncated\n",
    "    normal distribution. The values are effectively drawn from the\n",
    "    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n",
    "    with values outside :math:`[a, b]` redrawn until they are within\n",
    "    the bounds. The method used for generating the random values works\n",
    "    best when :math:`a \\leq \\text{mean} \\leq b`.\n",
    "    Args:\n",
    "        tensor: an n-dimensional `torch.Tensor`\n",
    "        mean: the mean of the normal distribution\n",
    "        std: the standard deviation of the normal distribution\n",
    "        a: the minimum cutoff value\n",
    "        b: the maximum cutoff value\n",
    "    Examples:\n",
    "        >>> w = torch.empty(3, 5)\n",
    "        >>> nn.init.trunc_normal_(w)\n",
    "    \"\"\"\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "\n",
    "def variance_scaling_(tensor, scale=1.0, mode='fan_in', distribution='normal'):\n",
    "    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n",
    "    if mode == 'fan_in':\n",
    "        denom = fan_in\n",
    "    elif mode == 'fan_out':\n",
    "        denom = fan_out\n",
    "    elif mode == 'fan_avg':\n",
    "        denom = (fan_in + fan_out) / 2\n",
    "\n",
    "    variance = scale / denom\n",
    "\n",
    "    if distribution == \"truncated_normal\":\n",
    "        # constant is stddev of standard normal truncated to (-2, 2)\n",
    "        trunc_normal_(tensor, std=math.sqrt(variance) / .87962566103423978)\n",
    "    elif distribution == \"normal\":\n",
    "        tensor.normal_(std=math.sqrt(variance))\n",
    "    elif distribution == \"uniform\":\n",
    "        bound = math.sqrt(3 * variance)\n",
    "        tensor.uniform_(-bound, bound)\n",
    "    else:\n",
    "        raise ValueError(f\"invalid distribution {distribution}\")\n",
    "\n",
    "\n",
    "def lecun_normal_(tensor):\n",
    "    variance_scaling_(tensor, mode='fan_in', distribution='truncated_normal')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pdb\n",
    "import math\n",
    "import random\n",
    "from numpy.core.fromnumeric import clip, reshape\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "# from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "# from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "from itertools import repeat\n",
    "from typing import List\n",
    "# from .layers import PatchEmbed, Mlp, DropPath, trunc_normal_, to_2tuple\n",
    "# from utils import do_mixup, interpolate\n",
    "\n",
    "    \n",
    "def interpolate(x, ratio):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the \n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    \n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "def do_mixup(x, mixup_lambda):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      x: (batch_size , ...)\n",
    "      mixup_lambda: (batch_size,)\n",
    "\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x.transpose(0,-1) * mixup_lambda + torch.flip(x, dims = [0]).transpose(0,-1) * (1 - mixup_lambda)).transpose(0,-1)\n",
    "    return out\n",
    "\n",
    "\n",
    "# below codes are based and referred from https://github.com/microsoft/Swin-Transformer\n",
    "# Swin Transformer for Computer Vision: https://arxiv.org/pdf/2103.14030.pdf\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x: (B, H, W, C)\n",
    "        window_size (int): window size\n",
    "    Returns:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, H, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        windows: (num_windows*B, window_size, window_size, C)\n",
    "        window_size (int): Window size\n",
    "        H (int): Height of image\n",
    "        W (int): Width of image\n",
    "    Returns:\n",
    "        x: (B, H, W, C)\n",
    "    \"\"\"\n",
    "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
    "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x\n",
    "\n",
    "\n",
    "class WindowAttention(nn.Module):\n",
    "    r\"\"\" Window based multi-head self attention (W-MSA) module with relative position bias.\n",
    "    It supports both of shifted and non-shifted window.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        window_size (tuple[int]): The height and width of the window.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set\n",
    "        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n",
    "        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        # define a parameter table of relative position bias\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input features with shape of (num_windows*B, N, C)\n",
    "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
    "        \"\"\"\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "\n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = self.softmax(attn)\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x, attn\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f'dim={self.dim}, window_size={self.window_size}, num_heads={self.num_heads}'\n",
    "\n",
    "\n",
    "# We use the model based on Swintransformer Block, therefore we can use the swin-transformer pretrained model\n",
    "class SwinTransformerBlock(nn.Module):\n",
    "    r\"\"\" Swin Transformer Block.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resulotion.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Window size.\n",
    "        shift_size (int): Shift size for SW-MSA.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
    "        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=nn.LayerNorm, norm_before_mlp='ln'):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        self.norm_before_mlp = norm_before_mlp\n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            # if window size is larger than input resolution, we don't partition windows\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "        assert 0 <= self.shift_size < self.window_size, \"shift_size must in 0-window_size\"\n",
    "\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        if self.norm_before_mlp == 'ln':\n",
    "            self.norm2 = nn.LayerNorm(dim)\n",
    "        elif self.norm_before_mlp == 'bn':\n",
    "            self.norm2 = lambda x: nn.BatchNorm1d(dim)(x.transpose(1, 2)).transpose(1, 2)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "        if self.shift_size > 0:\n",
    "            # calculate attention mask for SW-MSA\n",
    "            H, W = self.input_resolution\n",
    "            img_mask = torch.zeros((1, H, W, 1))  # 1 H W 1\n",
    "            h_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            w_slices = (slice(0, -self.window_size),\n",
    "                        slice(-self.window_size, -self.shift_size),\n",
    "                        slice(-self.shift_size, None))\n",
    "            cnt = 0\n",
    "            for h in h_slices:\n",
    "                for w in w_slices:\n",
    "                    img_mask[:, h, w, :] = cnt\n",
    "                    cnt += 1\n",
    "\n",
    "            mask_windows = window_partition(img_mask, self.window_size)  # nW, window_size, window_size, 1\n",
    "            mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n",
    "            attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n",
    "            attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
    "        else:\n",
    "            attn_mask = None\n",
    "\n",
    "        self.register_buffer(\"attn_mask\", attn_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pdb.set_trace()\n",
    "        H, W = self.input_resolution\n",
    "        # print(\"H: \", H)\n",
    "        # print(\"W: \", W)\n",
    "        # pdb.set_trace()\n",
    "        B, L, C = x.shape\n",
    "        # assert L == H * W, \"input feature has wrong size\"\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        # cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        # partition windows\n",
    "        x_windows = window_partition(shifted_x, self.window_size)  # nW*B, window_size, window_size, C\n",
    "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows, attn = self.attn(x_windows, mask=self.attn_mask)  # nW*B, window_size*window_size, C\n",
    "\n",
    "        # merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)  # B H' W' C\n",
    "\n",
    "        # reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C)\n",
    "\n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x, attn\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"window_size={self.window_size}, shift_size={self.shift_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "\n",
    "\n",
    "class PatchMerging(nn.Module):\n",
    "    r\"\"\" Patch Merging Layer.\n",
    "    Args:\n",
    "        input_resolution (tuple[int]): Resolution of input feature.\n",
    "        dim (int): Number of input channels.\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_resolution, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
    "        self.norm = norm_layer(4 * dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: B, H*W, C\n",
    "        \"\"\"\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
    "\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
    "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"input_resolution={self.input_resolution}, dim={self.dim}\"\n",
    "\n",
    "\n",
    "class BasicLayer(nn.Module):\n",
    "    \"\"\" A basic Swin Transformer layer for one stage.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resolution.\n",
    "        depth (int): Number of blocks.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Local window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n",
    "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n",
    "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., norm_layer=nn.LayerNorm, downsample=None, use_checkpoint=False,\n",
    "                 norm_before_mlp='ln'):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                                 num_heads=num_heads, window_size=window_size,\n",
    "                                 shift_size=0 if (i % 2 == 0) else window_size // 2,\n",
    "                                 mlp_ratio=mlp_ratio,\n",
    "                                 qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                                 drop=drop, attn_drop=attn_drop,\n",
    "                                 drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                                 norm_layer=norm_layer, norm_before_mlp=norm_before_mlp)\n",
    "            for i in range(depth)])\n",
    "\n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        attns = []\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x, attn = blk(x)\n",
    "                if not self.training:\n",
    "                    attns.append(attn.unsqueeze(0))\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        if not self.training:\n",
    "            attn = torch.cat(attns, dim = 0)\n",
    "            attn = torch.mean(attn, dim = 0)\n",
    "        return x, attn\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
    "\n",
    "\n",
    "# The Core of HTSAT\n",
    "class HTSAT_Swin_Transformer(nn.Module):\n",
    "    r\"\"\"HTSAT based on the Swin Transformer\n",
    "    Args:\n",
    "        spec_size (int | tuple(int)): Input Spectrogram size. Default 256\n",
    "        patch_size (int | tuple(int)): Patch size. Default: 4\n",
    "        path_stride (iot | tuple(int)): Patch Stride for Frequency and Time Axis. Default: 4\n",
    "        in_chans (int): Number of input image channels. Default: 1 (mono)\n",
    "        num_classes (int): Number of classes for classification head. Default: 527\n",
    "        embed_dim (int): Patch embedding dimension. Default: 96\n",
    "        depths (tuple(int)): Depth of each HTSAT-Swin Transformer layer.\n",
    "        num_heads (tuple(int)): Number of attention heads in different layers.\n",
    "        window_size (int): Window size. Default: 8\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4\n",
    "        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True\n",
    "        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. Default: None\n",
    "        drop_rate (float): Dropout rate. Default: 0\n",
    "        attn_drop_rate (float): Attention dropout rate. Default: 0\n",
    "        drop_path_rate (float): Stochastic depth rate. Default: 0.1\n",
    "        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n",
    "        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False\n",
    "        patch_norm (bool): If True, add normalization after patch embedding. Default: True\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False\n",
    "        config (module): The configuration Module from config.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "     spec_size=128, patch_size=4, patch_stride=(4,4), \n",
    "                in_chans=1, num_classes=1,\n",
    "                 embed_dim=96, depths=[2, 2, 6, 2], num_heads=[4, 8, 16, 32],\n",
    "                 window_size=8, mlp_ratio=4., qkv_bias=True, qk_scale=None,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1,\n",
    "                 norm_layer=nn.LayerNorm,  patch_norm=True,\n",
    "                 ape=False,\n",
    "                 use_checkpoint=False, norm_before_mlp='ln', config = None, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.spec_size = spec_size \n",
    "        self.patch_stride = patch_stride\n",
    "        self.patch_size = patch_size\n",
    "        self.window_size = window_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.depths = depths\n",
    "        self.ape = ape\n",
    "        self.in_chans = in_chans\n",
    "        self.num_classes = num_classes\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = len(self.depths)\n",
    "        self.num_features = int(self.embed_dim * 2 ** (self.num_layers - 1))\n",
    "        \n",
    "        self.drop_rate = drop_rate\n",
    "        self.attn_drop_rate = attn_drop_rate\n",
    "        self.drop_path_rate = drop_path_rate\n",
    "\n",
    "        self.qkv_bias = qkv_bias\n",
    "        self.qk_scale = None\n",
    "\n",
    "        self.patch_norm = patch_norm\n",
    "        self.norm_layer = norm_layer if self.patch_norm else None\n",
    "        self.norm_before_mlp = norm_before_mlp\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        #  process mel-spec ; used only once\n",
    "        self.freq_ratio = self.spec_size // self.config.mel_bins\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "        self.interpolate_ratio = 32     # Downsampled ratio\n",
    "        # Spectrogram extractor\n",
    "        # self.spectrogram_extractor = Spectrogram(n_fft=config.window_size, hop_length=config.hop_size, \n",
    "        #     win_length=config.window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "        #     freeze_parameters=True)\n",
    "        # Logmel feature extractor\n",
    "        # self.logmel_extractor = LogmelFilterBank(sr=config.sample_rate, n_fft=config.window_size, \n",
    "        #     n_mels=config.mel_bins, fmin=config.fmin, fmax=config.fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "        #     freeze_parameters=True)\n",
    "        # Spec augmenter\n",
    "        # self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "        #     freq_drop_width=8, freq_stripes_num=2) # 2 2\n",
    "\n",
    "        MEL_BINS = 128\n",
    "        self.bn0 = nn.BatchNorm2d(MEL_BINS)\n",
    "\n",
    "\n",
    "        # split spctrogram into non-overlapping patches\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=self.spec_size, patch_size=self.patch_size, in_chans=self.in_chans, \n",
    "            embed_dim=self.embed_dim, norm_layer=self.norm_layer, patch_stride = patch_stride)\n",
    "        \n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        patches_resolution = self.patch_embed.grid_size\n",
    "        # print(f\"num_patches: {num_patches}\")\n",
    "        self.patches_resolution = patches_resolution\n",
    "        # print(f\"patches_resolution: {patches_resolution}\")\n",
    "\n",
    "        # absolute position embedding\n",
    "        # if self.ape:\n",
    "        #     self.absolute_pos_embed = nn.Parameter(torch.zeros(1, num_patches, self.embed_dim))\n",
    "        #     trunc_normal_(self.absolute_pos_embed, std=.02)\n",
    "\n",
    "        self.pos_drop = nn.Dropout(p=self.drop_rate)\n",
    "\n",
    "        # stochastic depth\n",
    "        dpr = [x.item() for x in torch.linspace(0, self.drop_path_rate, sum(self.depths))]  # stochastic depth decay rule\n",
    "\n",
    "        # build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            layer = BasicLayer(dim=int(self.embed_dim * 2 ** i_layer),\n",
    "                input_resolution=(patches_resolution[0] // (2 ** i_layer),\n",
    "                                    patches_resolution[1] // (2 ** i_layer)),\n",
    "                depth=self.depths[i_layer],\n",
    "                num_heads=self.num_heads[i_layer],\n",
    "                window_size=self.window_size,\n",
    "                mlp_ratio=self.mlp_ratio,\n",
    "                qkv_bias=self.qkv_bias, qk_scale=self.qk_scale,\n",
    "                drop=self.drop_rate, attn_drop=self.attn_drop_rate,\n",
    "                drop_path=dpr[sum(self.depths[:i_layer]):sum(self.depths[:i_layer + 1])],\n",
    "                norm_layer=self.norm_layer,\n",
    "                downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n",
    "                use_checkpoint=use_checkpoint,\n",
    "                norm_before_mlp=self.norm_before_mlp)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.norm = self.norm_layer(self.num_features)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.maxpool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.head = nn.Linear(self.num_features, 1) \n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'absolute_pos_embed'}\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {'relative_position_bias_table'}\n",
    "\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        # A deprecated optimization for using a hierarchical output from different blocks\n",
    "        # if self.config.htsat_hier_output:\n",
    "        #     hier_x = []\n",
    "        #     hier_attn = []\n",
    "        # print(f\"forward_features(self, x): {x.shape}\")\n",
    "        # print(f\"forward_features [in], {}\")\n",
    "        \n",
    "        frames_num = x.shape[2]        \n",
    "        # print(f\"frames_num: {frames_num}\")\n",
    "        x = self.patch_embed(x)\n",
    "        # print(f\"forward_features[self.patch_embed(x)] [out]: {x.shape}\")\n",
    "        if self.ape:\n",
    "            x = x + self.absolute_pos_embed\n",
    "        \n",
    "        x = self.pos_drop(x)\n",
    "        # print(f\"forward_features[self.pos_drop(x)] [out]: {x.shape}\")\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x, attn = layer(x)\n",
    "\n",
    "        print(f\"forward_features[x, attn = layer(x)] [out]: {x.shape}\")\n",
    "        # print(f\"forward_features[enumerate(self.layers)] [out]: {x.shape}\")\n",
    "        x = self.norm(x)  # B N C\n",
    "        print(f\"forward_features[self.norm(x)] [out]: {x.shape}\")\n",
    "        B, N, C = x.shape\n",
    "        # orward_features[enumerate(self.layers)] [out]: torch.Size([11, 64, 768])\n",
    "        \n",
    "        fpx = x.permute(0,2,1).contiguous().reshape(B, C, frames_num // (2 ** (len(self.depths) + 1)), frames_num // (2 ** (len(self.depths) + 1)) )\n",
    "        # print(f\"fpx shape {fpx.shape}\")\n",
    "\n",
    "        B, C, F, T = fpx.shape\n",
    "\n",
    "        # framewise \n",
    "        c_freq_bin = F // self.freq_ratio\n",
    "        fpx = fpx.reshape(B, C, F // c_freq_bin, c_freq_bin, T)\n",
    "        fpx = fpx.permute(0,1,3,2,4).contiguous().reshape(B, C, c_freq_bin, -1)\n",
    "        fpx = torch.sum(fpx, dim = 2)\n",
    "        fpx = interpolate(fpx.permute(0,2,1).contiguous(), 8 * self.patch_stride[1]) \n",
    "        # framewise \n",
    "\n",
    "        x = self.avgpool(x.transpose(1, 2))  # B C 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.head(x)\n",
    "        # fpx = self.head(fpx)\n",
    "\n",
    "        output_dict = {\n",
    "            'framewise_output': fpx, \n",
    "            'clipwise_output': x\n",
    "            }\n",
    "        return output_dict\n",
    "\n",
    "    def crop_wav(self, x, crop_size, spe_pos = None):\n",
    "        time_steps = x.shape[2]\n",
    "        tx = torch.zeros(x.shape[0], x.shape[1], crop_size, x.shape[3]).to(x.device)\n",
    "        for i in range(len(x)):\n",
    "            if spe_pos is None:\n",
    "                crop_pos = random.randint(0, time_steps - crop_size - 1)\n",
    "            else:\n",
    "                crop_pos = spe_pos\n",
    "            tx[i][0] = x[i, 0, crop_pos:crop_pos + crop_size,:]\n",
    "        return tx\n",
    "\n",
    "    # Reshape the wavform to a img size, if you want to use the pretrained swin transformer model\n",
    "    def reshape_wav2img(self, x):\n",
    "        B, C, T, F = x.shape\n",
    "        target_T = int(self.spec_size * self.freq_ratio)\n",
    "        target_F = self.spec_size // self.freq_ratio\n",
    "        assert T <= target_T and F <= target_F, \"the wav size should less than or equal to the swin input size\"\n",
    "        # to avoid bicubic zero error\n",
    "        if T < target_T:\n",
    "            x = nn.functional.interpolate(x, (target_T, x.shape[3]), mode=\"bicubic\", align_corners=True)\n",
    "        if F < target_F:\n",
    "            x = nn.functional.interpolate(x, (x.shape[2], target_F), mode=\"bicubic\", align_corners=True)\n",
    "        x = x.permute(0,1,3,2).contiguous()\n",
    "        x = x.reshape(x.shape[0], x.shape[1], x.shape[2], self.freq_ratio, x.shape[3] // self.freq_ratio)\n",
    "        # print(x.shape)\n",
    "        x = x.permute(0,1,3,2,4).contiguous()\n",
    "        x = x.reshape(x.shape[0], x.shape[1], x.shape[2] * x.shape[3], x.shape[4])\n",
    "        return x\n",
    "    \n",
    "    # Repeat the wavform to a img size, if you want to use the pretrained swin transformer model\n",
    "    def repeat_wat2img(self, x, cur_pos):\n",
    "        B, C, T, F = x.shape\n",
    "        target_T = int(self.spec_size * self.freq_ratio)\n",
    "        target_F = self.spec_size // self.freq_ratio\n",
    "        assert T <= target_T and F <= target_F, \"the wav size should less than or equal to the swin input size\"\n",
    "        # to avoid bicubic zero error\n",
    "        if T < target_T:\n",
    "            x = nn.functional.interpolate(x, (target_T, x.shape[3]), mode=\"bicubic\", align_corners=True)\n",
    "        if F < target_F:\n",
    "            x = nn.functional.interpolate(x, (x.shape[2], target_F), mode=\"bicubic\", align_corners=True)  \n",
    "        x = x.permute(0,1,3,2).contiguous() # B C F T\n",
    "        x = x[:,:,:,cur_pos:cur_pos + self.spec_size]\n",
    "        x = x.repeat(repeats = (1,1,4,1))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mixup_lambda = None, infer_mode = False):# out_feat_keys: List[str] = None):\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)   \n",
    "        if infer_mode:\n",
    "            # in infer mode. we need to handle different length audio input\n",
    "            frame_num = x.shape[2]\n",
    "            target_T = int(self.spec_size * self.freq_ratio)\n",
    "            repeat_ratio = math.floor(target_T / frame_num)\n",
    "            x = x.repeat(repeats=(1,1,repeat_ratio,1))\n",
    "            x = self.reshape_wav2img(x)\n",
    "            output_dict = self.forward_features(x)\n",
    "        else:\n",
    "            x = self.reshape_wav2img(x)\n",
    "            output_dict = self.forward_features(x)\n",
    "        # x = x)\n",
    "        # from pprint import pprint \n",
    "        # print(\"Output dict\")\n",
    "        # for (k,v) in output_dict.items():\n",
    "        #     print(f\"{k} shape\", v.shape)\n",
    "        return output_dict['clipwise_output']\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "@dataclass \n",
    "class HTSATConfig:\n",
    "\n",
    "    loss_type = \"clip_ce\" # \n",
    "    # AudioSet & SCV2: \"clip_bce\" |  ESC-50: \"clip_ce\"     \n",
    "    esc_fold = 0 # just for esc dataset, select the fold you need for evaluation and (+1) validation\n",
    "    debug = False\n",
    "\n",
    "    random_seed = 970131 # 19970318 970131 12412 127777 1009 34047\n",
    "    # batch_size = 64 # batch size per GPU x GPU number , default is 32 x 4 = 128\n",
    "    # learning_rate = 1e-3 # 1e-4 also workable \n",
    "    # max_epoch = 100\n",
    "    # num_workers = 3\n",
    "    token_label_range = [0.2,0.6]\n",
    "    enable_time_shift = False # shift time\n",
    "    enable_label_enhance = False # enhance hierarchical label\n",
    "    enable_repeat_mode = False # repeat the spectrogram / reshape the spectrogram\n",
    "    # for model's design\n",
    "    # for signal processing\n",
    "    sample_rate = 16000 # 16000 for scv2, 32000 for audioset and esc-50\n",
    "    clip_samples = sample_rate * 10 # audio_set 10-sec clip\n",
    "    window_size = 1024\n",
    "    hop_size = 160 # 160 for scv2, 320 for audioset and esc-50\n",
    "    mel_bins = 128 \n",
    "    fmin = 50\n",
    "    fmax = 14000\n",
    "    shift_max = int(clip_samples * 0.5)\n",
    "    # for data collection\n",
    "    classes_num = 1 # esc: 50 | audioset: 527 | scv2: 35\n",
    "    patch_size = (25, 4) # deprecated\n",
    "    crop_size = None # int(clip_samples * 0.5) deprecated\n",
    "    # for htsat hyperparamater\n",
    "    htsat_window_size = 8\n",
    "    htsat_spec_size =  256\n",
    "    htsat_patch_size = 4 \n",
    "    htsat_stride = (4, 4)\n",
    "    htsat_num_head = [4,8,16,32]\n",
    "    htsat_dim = 96 \n",
    "    htsat_depth = [2,2,6,2]\n",
    "    swin_pretrain_path = None\n",
    "    # \"/home/Research/model_backup/pretrain/swin_tiny_c24_patch4_window8_256.pth\"\n",
    "    # Some Deprecated Optimization in the model design, check the model code for details\n",
    "    htsat_attn_heatmap = False\n",
    "    htsat_hier_output = False \n",
    "    htsat_use_max = False\n",
    "    # for ensemble test \n",
    "    ensemble_checkpoints = []\n",
    "    ensemble_strides = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from nnAudio import features\n",
    "import torchaudio \n",
    "\n",
    "\n",
    "from wwv.data import AudioDataModule\n",
    "from wwv.config import DataPaths\n",
    "import torchaudio \n",
    "cfg = Config(params)\n",
    "data_path = DataPaths(cfg.path['data_dir'], cfg.model_name, cfg.path['model_dir'])\n",
    "data_module = AudioDataModule(data_path.root_data_dir + \"/train.csv\",\n",
    "                              data_path.root_data_dir + \"/val.csv\",\n",
    "                              data_path.root_data_dir + \"/test.csv\",\n",
    "                              cfg=cfg)\n",
    "                              \n",
    "train_loader =  data_module.train_dataloader()\n",
    "val_loader =  data_module.val_dataloader()\n",
    "test_loader =  data_module.test_dataloader()\n",
    "\n",
    "x = next(iter(train_loader))\n",
    "\n",
    "config = HTSATConfig()\n",
    "\n",
    "sed_model = HTSAT_Swin_Transformer(\n",
    "    spec_size=config.htsat_spec_size,\n",
    "    patch_size=config.htsat_patch_size,\n",
    "    in_chans=1,\n",
    "    num_classes=config.classes_num,\n",
    "    window_size=config.htsat_window_size,\n",
    "    config = config,\n",
    "    depths = config.htsat_depth,\n",
    "    embed_dim = config.htsat_dim,\n",
    "    patch_stride=config.htsat_stride,\n",
    "    num_heads=config.htsat_num_head\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F \n",
    "from wwv.architecture import Architecture\n",
    "from wwv.eval import Metric\n",
    "from wwv.data import AudioDataModule\n",
    "from wwv.config import  DataPaths\n",
    "import statistics\n",
    "# data_path = DataPaths(cfg.path['data_dir'], cfg.model_name, cfg.path['model_dir'])\n",
    "cfg = Config(params)\n",
    "# model = Architecture(cfg, training=True)\n",
    "# model.extractor(torch.randn((1,48000))) # (torch.randn((1,48000)))\n",
    "root = \"/home/akinwilson/Code/pytorch/dataset/keywords\"\n",
    "# data_module = AudioDataModule(data_path.root_data_dir + \"/train.csv\",\n",
    "#                               data_path.root_data_dir + \"/val.csv\",\n",
    "#                               data_path.root_data_dir + \"/test.csv\",\n",
    "#                                cfg)\n",
    "# # model.processing_layer[3](x)\n",
    "# train_loader=  data_module.train_dataloader()\n",
    "# val_loader=  data_module.val_dataloader()\n",
    "# channel, n_mels, time  = [1, 128, 114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as  nn\n",
    "import torch.nn.functional as F\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from nnAudio import features\n",
    "import torchaudio \n",
    "\n",
    "from wwv.data import AudioDataModule\n",
    "from wwv.config import DataPaths\n",
    "import torchaudio \n",
    "cfg = Config(params)\n",
    "data_path = DataPaths(cfg.path['data_dir'], cfg.model_name, cfg.path['model_dir'])\n",
    "data_module = AudioDataModule(data_path.root_data_dir + \"/train.csv\",\n",
    "                              data_path.root_data_dir + \"/val.csv\",\n",
    "                              data_path.root_data_dir + \"/test.csv\",\n",
    "                              cfg=cfg)\n",
    "                              \n",
    "train_loader =  data_module.train_dataloader()\n",
    "val_loader =  data_module.val_dataloader()\n",
    "test_loader =  data_module.test_dataloader()\n",
    "\n",
    "x = next(iter(train_loader))\n",
    "\n",
    "# x['x'].shape\n",
    "# channel,  time, n_mels = [1, 241, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a temporary directory at /tmp/tmpbv_6s4ka\n",
      "Created a temporary directory at /tmp/tmpbv_6s4ka\n",
      "Created a temporary directory at /tmp/tmpbv_6s4ka\n",
      "Created a temporary directory at /tmp/tmpbv_6s4ka\n",
      "Writing /tmp/tmpbv_6s4ka/_remote_module_non_scriptable.py\n",
      "Writing /tmp/tmpbv_6s4ka/_remote_module_non_scriptable.py\n",
      "Writing /tmp/tmpbv_6s4ka/_remote_module_non_scriptable.py\n",
      "Writing /tmp/tmpbv_6s4ka/_remote_module_non_scriptable.py\n",
      "GPU available: True (cuda), used: True\n",
      "GPU available: True (cuda), used: True\n",
      "GPU available: True (cuda), used: True\n",
      "GPU available: True (cuda), used: True\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name  | Type                   | Params\n",
      "-------------------------------------------------\n",
      "0 | model | HTSAT_Swin_Transformer | 27.5 M\n",
      "-------------------------------------------------\n",
      "27.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 M    Total params\n",
      "110.142   Total estimated model params size (MB)\n",
      "\n",
      "  | Name  | Type                   | Params\n",
      "-------------------------------------------------\n",
      "0 | model | HTSAT_Swin_Transformer | 27.5 M\n",
      "-------------------------------------------------\n",
      "27.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 M    Total params\n",
      "110.142   Total estimated model params size (MB)\n",
      "\n",
      "  | Name  | Type                   | Params\n",
      "-------------------------------------------------\n",
      "0 | model | HTSAT_Swin_Transformer | 27.5 M\n",
      "-------------------------------------------------\n",
      "27.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 M    Total params\n",
      "110.142   Total estimated model params size (MB)\n",
      "\n",
      "  | Name  | Type                   | Params\n",
      "-------------------------------------------------\n",
      "0 | model | HTSAT_Swin_Transformer | 27.5 M\n",
      "-------------------------------------------------\n",
      "27.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 M    Total params\n",
      "110.142   Total estimated model params size (MB)\n",
      "\n",
      "  | Name  | Type                   | Params\n",
      "-------------------------------------------------\n",
      "0 | model | HTSAT_Swin_Transformer | 27.5 M\n",
      "-------------------------------------------------\n",
      "27.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "27.5 M    Total params\n",
      "110.142   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:03<00:03,  3.92s/it]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 0:   0%|          | 0/27 [00:00<?, ?it/s]                            forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 0:   4%|▎         | 1/27 [00:00<00:15,  1.63it/s, loss=0.793, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 0:   7%|▋         | 2/27 [00:00<00:10,  2.41it/s, loss=0.895, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  11%|█         | 3/27 [00:01<00:08,  2.91it/s, loss=0.879, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  15%|█▍        | 4/27 [00:01<00:07,  3.25it/s, loss=0.82, v_num=1] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  19%|█▊        | 5/27 [00:01<00:06,  3.50it/s, loss=0.769, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  22%|██▏       | 6/27 [00:01<00:05,  3.69it/s, loss=0.751, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  26%|██▌       | 7/27 [00:01<00:05,  3.83it/s, loss=0.737, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  30%|██▉       | 8/27 [00:02<00:04,  3.96it/s, loss=0.712, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  33%|███▎      | 9/27 [00:02<00:04,  4.05it/s, loss=0.688, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  37%|███▋      | 10/27 [00:02<00:04,  4.14it/s, loss=0.681, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  41%|████      | 11/27 [00:02<00:03,  4.20it/s, loss=0.685, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  44%|████▍     | 12/27 [00:02<00:03,  4.27it/s, loss=0.674, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  48%|████▊     | 13/27 [00:03<00:03,  4.31it/s, loss=0.689, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 0:  52%|█████▏    | 14/27 [00:03<00:03,  4.24it/s, loss=0.687, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  56%|█████▌    | 15/27 [00:03<00:02,  4.29it/s, loss=0.676, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  59%|█████▉    | 16/27 [00:03<00:02,  4.33it/s, loss=0.664, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  63%|██████▎   | 17/27 [00:03<00:02,  4.37it/s, loss=0.669, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  67%|██████▋   | 18/27 [00:04<00:02,  4.40it/s, loss=0.664, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  70%|███████   | 19/27 [00:04<00:01,  4.44it/s, loss=0.662, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 0:  74%|███████▍  | 20/27 [00:04<00:01,  4.46it/s, loss=0.658, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 0:  78%|███████▊  | 21/27 [00:04<00:01,  4.49it/s, loss=0.647, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  81%|████████▏ | 22/27 [00:04<00:01,  4.51it/s, loss=0.629, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  85%|████████▌ | 23/27 [00:05<00:00,  4.53it/s, loss=0.611, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  89%|████████▉ | 24/27 [00:05<00:00,  4.54it/s, loss=0.601, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  93%|█████████▎| 25/27 [00:05<00:00,  4.56it/s, loss=0.601, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 0:  96%|█████████▋| 26/27 [00:05<00:00,  4.64it/s, loss=0.601, v_num=1]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.601, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:   4%|▎         | 1/27 [00:00<00:05,  5.13it/s, loss=0.59, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:   7%|▋         | 2/27 [00:00<00:04,  5.04it/s, loss=0.58, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  11%|█         | 3/27 [00:00<00:04,  5.07it/s, loss=0.586, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  15%|█▍        | 4/27 [00:00<00:04,  5.06it/s, loss=0.602, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  19%|█▊        | 5/27 [00:00<00:04,  5.06it/s, loss=0.608, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  22%|██▏       | 6/27 [00:01<00:04,  5.05it/s, loss=0.608, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  26%|██▌       | 7/27 [00:01<00:03,  5.06it/s, loss=0.614, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  30%|██▉       | 8/27 [00:01<00:03,  5.07it/s, loss=0.607, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  33%|███▎      | 9/27 [00:01<00:03,  5.06it/s, loss=0.606, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  37%|███▋      | 10/27 [00:01<00:03,  5.06it/s, loss=0.613, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  41%|████      | 11/27 [00:02<00:03,  5.05it/s, loss=0.625, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  44%|████▍     | 12/27 [00:02<00:02,  5.06it/s, loss=0.623, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  48%|████▊     | 13/27 [00:02<00:02,  5.05it/s, loss=0.627, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  52%|█████▏    | 14/27 [00:02<00:02,  5.05it/s, loss=0.625, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  56%|█████▌    | 15/27 [00:02<00:02,  5.05it/s, loss=0.627, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  59%|█████▉    | 16/27 [00:03<00:02,  5.05it/s, loss=0.615, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  63%|██████▎   | 17/27 [00:03<00:01,  5.05it/s, loss=0.621, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  67%|██████▋   | 18/27 [00:03<00:01,  5.06it/s, loss=0.629, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  70%|███████   | 19/27 [00:03<00:01,  5.05it/s, loss=0.631, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  74%|███████▍  | 20/27 [00:03<00:01,  5.05it/s, loss=0.632, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  78%|███████▊  | 21/27 [00:04<00:01,  5.05it/s, loss=0.64, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  81%|████████▏ | 22/27 [00:04<00:00,  5.05it/s, loss=0.656, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  85%|████████▌ | 23/27 [00:04<00:00,  5.05it/s, loss=0.652, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 1:  89%|████████▉ | 24/27 [00:04<00:00,  5.05it/s, loss=0.633, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  93%|█████████▎| 25/27 [00:04<00:00,  5.05it/s, loss=0.628, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 1:  96%|█████████▋| 26/27 [00:05<00:00,  5.13it/s, loss=0.628, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.800, train_loss=0.635, train_ttr=0.0347, train_ftr=0.0385, train_acc=0.729]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.628, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:   4%|▎         | 1/27 [00:00<00:05,  4.69it/s, loss=0.62, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:   7%|▋         | 2/27 [00:00<00:05,  4.79it/s, loss=0.616, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  11%|█         | 3/27 [00:00<00:04,  4.93it/s, loss=0.607, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:  15%|█▍        | 4/27 [00:00<00:04,  4.98it/s, loss=0.605, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  19%|█▊        | 5/27 [00:00<00:04,  5.00it/s, loss=0.607, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:  22%|██▏       | 6/27 [00:01<00:04,  5.03it/s, loss=0.601, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  26%|██▌       | 7/27 [00:01<00:03,  5.05it/s, loss=0.6, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]  forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  30%|██▉       | 8/27 [00:01<00:03,  5.05it/s, loss=0.59, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  33%|███▎      | 9/27 [00:01<00:03,  5.06it/s, loss=0.591, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:  37%|███▋      | 10/27 [00:01<00:03,  5.05it/s, loss=0.587, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:  41%|████      | 11/27 [00:02<00:03,  5.05it/s, loss=0.599, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  44%|████▍     | 12/27 [00:02<00:02,  5.05it/s, loss=0.585, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  48%|████▊     | 13/27 [00:02<00:02,  5.05it/s, loss=0.579, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  52%|█████▏    | 14/27 [00:02<00:02,  5.03it/s, loss=0.585, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:  56%|█████▌    | 15/27 [00:02<00:02,  5.04it/s, loss=0.586, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  59%|█████▉    | 16/27 [00:03<00:02,  5.03it/s, loss=0.589, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  63%|██████▎   | 17/27 [00:03<00:01,  5.04it/s, loss=0.574, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  67%|██████▋   | 18/27 [00:03<00:01,  5.04it/s, loss=0.573, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  70%|███████   | 19/27 [00:03<00:01,  5.04it/s, loss=0.584, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:  74%|███████▍  | 20/27 [00:03<00:01,  5.04it/s, loss=0.583, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:  78%|███████▊  | 21/27 [00:04<00:01,  5.04it/s, loss=0.582, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:  81%|████████▏ | 22/27 [00:04<00:00,  5.04it/s, loss=0.579, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  85%|████████▌ | 23/27 [00:04<00:00,  5.05it/s, loss=0.578, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 2:  89%|████████▉ | 24/27 [00:04<00:00,  5.05it/s, loss=0.576, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  93%|█████████▎| 25/27 [00:04<00:00,  5.05it/s, loss=0.572, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 2:  96%|█████████▋| 26/27 [00:05<00:00,  5.13it/s, loss=0.572, v_num=1, val_loss=0.522, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.626, train_ttr=0.0284, train_ftr=0.0642, train_acc=0.710]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.572, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]           forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:   4%|▎         | 1/27 [00:00<00:05,  5.02it/s, loss=0.569, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 3:   7%|▋         | 2/27 [00:00<00:04,  5.03it/s, loss=0.569, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  11%|█         | 3/27 [00:00<00:04,  5.06it/s, loss=0.571, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  15%|█▍        | 4/27 [00:00<00:04,  5.05it/s, loss=0.565, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  19%|█▊        | 5/27 [00:00<00:04,  5.05it/s, loss=0.565, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  22%|██▏       | 6/27 [00:01<00:04,  5.06it/s, loss=0.563, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  26%|██▌       | 7/27 [00:01<00:04,  4.79it/s, loss=0.576, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  30%|██▉       | 8/27 [00:01<00:03,  4.83it/s, loss=0.575, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  33%|███▎      | 9/27 [00:01<00:03,  4.86it/s, loss=0.571, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  37%|███▋      | 10/27 [00:02<00:03,  4.88it/s, loss=0.567, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  41%|████      | 11/27 [00:02<00:03,  4.89it/s, loss=0.564, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  44%|████▍     | 12/27 [00:02<00:03,  4.91it/s, loss=0.567, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  48%|████▊     | 13/27 [00:02<00:02,  4.92it/s, loss=0.561, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  52%|█████▏    | 14/27 [00:02<00:02,  4.93it/s, loss=0.555, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 3:  56%|█████▌    | 15/27 [00:03<00:02,  4.93it/s, loss=0.551, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 3:  59%|█████▉    | 16/27 [00:03<00:02,  4.93it/s, loss=0.55, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  63%|██████▎   | 17/27 [00:03<00:02,  4.93it/s, loss=0.554, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  67%|██████▋   | 18/27 [00:03<00:01,  4.92it/s, loss=0.566, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  70%|███████   | 19/27 [00:03<00:01,  4.93it/s, loss=0.561, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  74%|███████▍  | 20/27 [00:04<00:01,  4.93it/s, loss=0.567, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  78%|███████▊  | 21/27 [00:04<00:01,  4.94it/s, loss=0.568, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 3:  81%|████████▏ | 22/27 [00:04<00:01,  4.94it/s, loss=0.563, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  85%|████████▌ | 23/27 [00:04<00:00,  4.93it/s, loss=0.566, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  89%|████████▉ | 24/27 [00:04<00:00,  4.93it/s, loss=0.574, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  93%|█████████▎| 25/27 [00:05<00:00,  4.93it/s, loss=0.582, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 3:  96%|█████████▋| 26/27 [00:05<00:00,  5.01it/s, loss=0.582, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.582, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:   4%|▎         | 1/27 [00:00<00:05,  5.05it/s, loss=0.586, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:   7%|▋         | 2/27 [00:00<00:04,  5.01it/s, loss=0.584, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  11%|█         | 3/27 [00:00<00:04,  4.95it/s, loss=0.581, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  15%|█▍        | 4/27 [00:00<00:04,  4.96it/s, loss=0.582, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  19%|█▊        | 5/27 [00:01<00:04,  4.95it/s, loss=0.58, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  22%|██▏       | 6/27 [00:01<00:04,  4.93it/s, loss=0.578, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  26%|██▌       | 7/27 [00:01<00:04,  4.96it/s, loss=0.582, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  30%|██▉       | 8/27 [00:01<00:03,  4.97it/s, loss=0.604, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  33%|███▎      | 9/27 [00:01<00:03,  4.99it/s, loss=0.607, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  37%|███▋      | 10/27 [00:02<00:03,  4.98it/s, loss=0.61, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  41%|████      | 11/27 [00:02<00:03,  4.99it/s, loss=0.608, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  44%|████▍     | 12/27 [00:02<00:03,  4.99it/s, loss=0.608, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  48%|████▊     | 13/27 [00:02<00:02,  4.99it/s, loss=0.596, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  52%|█████▏    | 14/27 [00:02<00:02,  5.00it/s, loss=0.605, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  56%|█████▌    | 15/27 [00:02<00:02,  5.01it/s, loss=0.595, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  59%|█████▉    | 16/27 [00:03<00:02,  5.01it/s, loss=0.599, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  63%|██████▎   | 17/27 [00:03<00:01,  5.02it/s, loss=0.603, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  67%|██████▋   | 18/27 [00:03<00:01,  5.02it/s, loss=0.603, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  70%|███████   | 19/27 [00:03<00:01,  5.02it/s, loss=0.597, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  74%|███████▍  | 20/27 [00:03<00:01,  5.03it/s, loss=0.587, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  78%|███████▊  | 21/27 [00:04<00:01,  5.04it/s, loss=0.581, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 4:  81%|████████▏ | 22/27 [00:04<00:00,  5.03it/s, loss=0.577, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  85%|████████▌ | 23/27 [00:04<00:00,  5.04it/s, loss=0.58, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  89%|████████▉ | 24/27 [00:04<00:00,  5.04it/s, loss=0.581, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  93%|█████████▎| 25/27 [00:04<00:00,  5.05it/s, loss=0.583, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 4:  96%|█████████▋| 26/27 [00:05<00:00,  5.12it/s, loss=0.583, v_num=1, val_loss=0.508, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.583, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:   4%|▎         | 1/27 [00:00<00:05,  4.89it/s, loss=0.597, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:   7%|▋         | 2/27 [00:00<00:05,  4.99it/s, loss=0.591, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  11%|█         | 3/27 [00:00<00:04,  5.06it/s, loss=0.576, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  15%|█▍        | 4/27 [00:00<00:04,  5.08it/s, loss=0.58, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  19%|█▊        | 5/27 [00:00<00:04,  5.09it/s, loss=0.576, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  22%|██▏       | 6/27 [00:01<00:04,  5.06it/s, loss=0.579, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  26%|██▌       | 7/27 [00:01<00:03,  5.06it/s, loss=0.578, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  30%|██▉       | 8/27 [00:01<00:03,  5.05it/s, loss=0.584, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  33%|███▎      | 9/27 [00:01<00:03,  5.05it/s, loss=0.587, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  37%|███▋      | 10/27 [00:01<00:03,  5.06it/s, loss=0.594, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  41%|████      | 11/27 [00:02<00:03,  5.06it/s, loss=0.585, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  44%|████▍     | 12/27 [00:02<00:02,  5.04it/s, loss=0.581, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  48%|████▊     | 13/27 [00:02<00:02,  5.05it/s, loss=0.584, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  52%|█████▏    | 14/27 [00:02<00:02,  5.04it/s, loss=0.585, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  56%|█████▌    | 15/27 [00:02<00:02,  5.04it/s, loss=0.585, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  59%|█████▉    | 16/27 [00:03<00:02,  5.05it/s, loss=0.589, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  63%|██████▎   | 17/27 [00:03<00:01,  5.03it/s, loss=0.58, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  67%|██████▋   | 18/27 [00:03<00:01,  5.04it/s, loss=0.582, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  70%|███████   | 19/27 [00:03<00:01,  5.05it/s, loss=0.583, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  74%|███████▍  | 20/27 [00:03<00:01,  5.05it/s, loss=0.588, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  78%|███████▊  | 21/27 [00:04<00:01,  5.05it/s, loss=0.57, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  81%|████████▏ | 22/27 [00:04<00:00,  5.06it/s, loss=0.572, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  85%|████████▌ | 23/27 [00:04<00:00,  4.97it/s, loss=0.574, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 5:  89%|████████▉ | 24/27 [00:04<00:00,  4.97it/s, loss=0.563, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  93%|█████████▎| 25/27 [00:05<00:00,  4.97it/s, loss=0.562, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 5:  96%|█████████▋| 26/27 [00:05<00:00,  5.05it/s, loss=0.562, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.578, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.562, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:   4%|▎         | 1/27 [00:00<00:05,  5.02it/s, loss=0.564, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:   7%|▋         | 2/27 [00:00<00:04,  5.12it/s, loss=0.555, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  11%|█         | 3/27 [00:00<00:04,  5.12it/s, loss=0.553, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  15%|█▍        | 4/27 [00:00<00:04,  5.13it/s, loss=0.55, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  19%|█▊        | 5/27 [00:00<00:04,  5.11it/s, loss=0.544, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  22%|██▏       | 6/27 [00:01<00:04,  5.12it/s, loss=0.552, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  26%|██▌       | 7/27 [00:01<00:03,  5.13it/s, loss=0.554, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  30%|██▉       | 8/27 [00:01<00:03,  5.13it/s, loss=0.555, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  33%|███▎      | 9/27 [00:01<00:03,  5.13it/s, loss=0.556, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  37%|███▋      | 10/27 [00:01<00:03,  5.13it/s, loss=0.557, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  41%|████      | 11/27 [00:02<00:03,  5.13it/s, loss=0.563, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  44%|████▍     | 12/27 [00:02<00:02,  5.13it/s, loss=0.562, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  48%|████▊     | 13/27 [00:02<00:02,  5.13it/s, loss=0.558, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  52%|█████▏    | 14/27 [00:02<00:02,  5.13it/s, loss=0.56, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  56%|█████▌    | 15/27 [00:02<00:02,  5.13it/s, loss=0.548, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  59%|█████▉    | 16/27 [00:03<00:02,  5.13it/s, loss=0.563, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  63%|██████▎   | 17/27 [00:03<00:01,  5.13it/s, loss=0.578, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  67%|██████▋   | 18/27 [00:03<00:01,  5.13it/s, loss=0.586, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  70%|███████   | 19/27 [00:03<00:01,  5.13it/s, loss=0.59, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  74%|███████▍  | 20/27 [00:03<00:01,  5.13it/s, loss=0.593, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  78%|███████▊  | 21/27 [00:04<00:01,  5.13it/s, loss=0.592, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  81%|████████▏ | 22/27 [00:04<00:00,  5.13it/s, loss=0.599, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  85%|████████▌ | 23/27 [00:04<00:00,  5.14it/s, loss=0.598, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 6:  89%|████████▉ | 24/27 [00:04<00:00,  5.14it/s, loss=0.598, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  93%|█████████▎| 25/27 [00:04<00:00,  5.14it/s, loss=0.598, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 6:  96%|█████████▋| 26/27 [00:04<00:00,  5.22it/s, loss=0.598, v_num=1, val_loss=0.512, val_ttr=0.000, val_ftr=0.000, val_acc=0.794, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.598, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:   4%|▎         | 1/27 [00:00<00:05,  5.14it/s, loss=0.59, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:   7%|▋         | 2/27 [00:00<00:04,  5.15it/s, loss=0.59, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  11%|█         | 3/27 [00:00<00:04,  5.15it/s, loss=0.592, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  15%|█▍        | 4/27 [00:00<00:04,  5.15it/s, loss=0.6, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]  forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  19%|█▊        | 5/27 [00:00<00:04,  5.13it/s, loss=0.592, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  22%|██▏       | 6/27 [00:01<00:04,  5.13it/s, loss=0.586, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  26%|██▌       | 7/27 [00:01<00:03,  5.14it/s, loss=0.596, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  30%|██▉       | 8/27 [00:01<00:03,  5.14it/s, loss=0.589, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  33%|███▎      | 9/27 [00:01<00:03,  5.15it/s, loss=0.582, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  37%|███▋      | 10/27 [00:01<00:03,  5.15it/s, loss=0.602, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  41%|████      | 11/27 [00:02<00:03,  5.15it/s, loss=0.589, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  44%|████▍     | 12/27 [00:02<00:02,  5.14it/s, loss=0.57, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  48%|████▊     | 13/27 [00:02<00:02,  5.14it/s, loss=0.564, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  52%|█████▏    | 14/27 [00:02<00:02,  5.14it/s, loss=0.567, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  56%|█████▌    | 15/27 [00:02<00:02,  5.14it/s, loss=0.566, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  59%|█████▉    | 16/27 [00:03<00:02,  5.14it/s, loss=0.569, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  63%|██████▎   | 17/27 [00:03<00:01,  5.14it/s, loss=0.574, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  67%|██████▋   | 18/27 [00:03<00:01,  5.14it/s, loss=0.569, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  70%|███████   | 19/27 [00:03<00:01,  5.14it/s, loss=0.568, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  74%|███████▍  | 20/27 [00:03<00:01,  5.13it/s, loss=0.569, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  78%|███████▊  | 21/27 [00:04<00:01,  5.02it/s, loss=0.578, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  81%|████████▏ | 22/27 [00:04<00:00,  5.02it/s, loss=0.578, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  85%|████████▌ | 23/27 [00:04<00:00,  5.02it/s, loss=0.576, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  89%|████████▉ | 24/27 [00:04<00:00,  5.01it/s, loss=0.568, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 7:  93%|█████████▎| 25/27 [00:04<00:00,  5.00it/s, loss=0.576, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 7:  96%|█████████▋| 26/27 [00:05<00:00,  5.07it/s, loss=0.576, v_num=1, val_loss=0.538, val_ttr=0.000, val_ftr=0.000, val_acc=0.777, train_loss=0.590, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.576, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:   4%|▎         | 1/27 [00:00<00:05,  5.03it/s, loss=0.579, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:   7%|▋         | 2/27 [00:00<00:04,  5.06it/s, loss=0.575, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  11%|█         | 3/27 [00:00<00:04,  5.06it/s, loss=0.586, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  15%|█▍        | 4/27 [00:00<00:04,  5.07it/s, loss=0.591, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  19%|█▊        | 5/27 [00:00<00:04,  5.07it/s, loss=0.582, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  22%|██▏       | 6/27 [00:01<00:04,  5.07it/s, loss=0.587, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  26%|██▌       | 7/27 [00:01<00:03,  5.07it/s, loss=0.589, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  30%|██▉       | 8/27 [00:01<00:03,  5.06it/s, loss=0.586, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  33%|███▎      | 9/27 [00:01<00:03,  5.05it/s, loss=0.58, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  37%|███▋      | 10/27 [00:01<00:03,  5.06it/s, loss=0.575, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  41%|████      | 11/27 [00:02<00:03,  5.06it/s, loss=0.58, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  44%|████▍     | 12/27 [00:02<00:02,  5.07it/s, loss=0.579, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  48%|████▊     | 13/27 [00:02<00:02,  5.07it/s, loss=0.585, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  52%|█████▏    | 14/27 [00:02<00:02,  5.07it/s, loss=0.579, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  56%|█████▌    | 15/27 [00:02<00:02,  5.08it/s, loss=0.586, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  59%|█████▉    | 16/27 [00:03<00:02,  5.07it/s, loss=0.58, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  63%|██████▎   | 17/27 [00:03<00:01,  5.08it/s, loss=0.574, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  67%|██████▋   | 18/27 [00:03<00:01,  5.08it/s, loss=0.572, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 8:  70%|███████   | 19/27 [00:03<00:01,  5.08it/s, loss=0.567, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  74%|███████▍  | 20/27 [00:03<00:01,  5.08it/s, loss=0.568, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  78%|███████▊  | 21/27 [00:04<00:01,  5.08it/s, loss=0.566, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  81%|████████▏ | 22/27 [00:04<00:00,  5.07it/s, loss=0.568, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  85%|████████▌ | 23/27 [00:04<00:00,  5.07it/s, loss=0.568, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  89%|████████▉ | 24/27 [00:04<00:00,  5.07it/s, loss=0.566, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  93%|█████████▎| 25/27 [00:04<00:00,  5.07it/s, loss=0.572, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 8:  96%|█████████▋| 26/27 [00:05<00:00,  5.15it/s, loss=0.572, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.572, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:   4%|▎         | 1/27 [00:00<00:05,  4.95it/s, loss=0.572, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:   7%|▋         | 2/27 [00:00<00:04,  5.04it/s, loss=0.569, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  11%|█         | 3/27 [00:00<00:04,  5.07it/s, loss=0.566, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  15%|█▍        | 4/27 [00:00<00:04,  5.07it/s, loss=0.572, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  19%|█▊        | 5/27 [00:00<00:04,  5.07it/s, loss=0.579, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  22%|██▏       | 6/27 [00:01<00:04,  5.08it/s, loss=0.57, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  26%|██▌       | 7/27 [00:01<00:03,  5.08it/s, loss=0.57, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  30%|██▉       | 8/27 [00:01<00:03,  5.08it/s, loss=0.569, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  33%|███▎      | 9/27 [00:01<00:03,  5.09it/s, loss=0.569, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  37%|███▋      | 10/27 [00:01<00:03,  5.09it/s, loss=0.566, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  41%|████      | 11/27 [00:02<00:03,  5.09it/s, loss=0.572, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  44%|████▍     | 12/27 [00:02<00:03,  4.92it/s, loss=0.58, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  48%|████▊     | 13/27 [00:02<00:02,  4.93it/s, loss=0.582, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  52%|█████▏    | 14/27 [00:02<00:02,  4.94it/s, loss=0.582, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  56%|█████▌    | 15/27 [00:03<00:02,  4.95it/s, loss=0.581, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  59%|█████▉    | 16/27 [00:03<00:02,  4.96it/s, loss=0.581, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  63%|██████▎   | 17/27 [00:03<00:02,  4.96it/s, loss=0.576, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  67%|██████▋   | 18/27 [00:03<00:01,  4.97it/s, loss=0.578, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  70%|███████   | 19/27 [00:03<00:01,  4.97it/s, loss=0.579, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  74%|███████▍  | 20/27 [00:04<00:01,  4.98it/s, loss=0.569, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  78%|███████▊  | 21/27 [00:04<00:01,  4.98it/s, loss=0.569, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  81%|████████▏ | 22/27 [00:04<00:01,  4.99it/s, loss=0.581, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 9:  85%|████████▌ | 23/27 [00:04<00:00,  4.99it/s, loss=0.586, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  89%|████████▉ | 24/27 [00:04<00:00,  4.99it/s, loss=0.582, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  93%|█████████▎| 25/27 [00:05<00:00,  5.00it/s, loss=0.582, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 9:  96%|█████████▋| 26/27 [00:05<00:00,  5.07it/s, loss=0.582, v_num=1, val_loss=0.567, val_ttr=0.000, val_ftr=0.000, val_acc=0.747, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.582, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]        forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:   4%|▎         | 1/27 [00:00<00:05,  5.05it/s, loss=0.585, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:   7%|▋         | 2/27 [00:00<00:04,  5.03it/s, loss=0.584, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:  11%|█         | 3/27 [00:00<00:04,  5.04it/s, loss=0.583, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  15%|█▍        | 4/27 [00:00<00:04,  5.04it/s, loss=0.586, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:  19%|█▊        | 5/27 [00:00<00:04,  5.04it/s, loss=0.581, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  22%|██▏       | 6/27 [00:01<00:04,  5.04it/s, loss=0.579, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  26%|██▌       | 7/27 [00:01<00:03,  5.05it/s, loss=0.572, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  30%|██▉       | 8/27 [00:01<00:03,  5.05it/s, loss=0.574, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:  33%|███▎      | 9/27 [00:01<00:03,  5.06it/s, loss=0.584, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  37%|███▋      | 10/27 [00:01<00:03,  5.05it/s, loss=0.584, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  41%|████      | 11/27 [00:02<00:03,  5.06it/s, loss=0.594, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  44%|████▍     | 12/27 [00:02<00:02,  5.06it/s, loss=0.598, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:  48%|████▊     | 13/27 [00:02<00:02,  5.06it/s, loss=0.592, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:  52%|█████▏    | 14/27 [00:02<00:02,  5.05it/s, loss=0.593, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:  56%|█████▌    | 15/27 [00:02<00:02,  5.05it/s, loss=0.599, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  59%|█████▉    | 16/27 [00:03<00:02,  5.05it/s, loss=0.593, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:  63%|██████▎   | 17/27 [00:03<00:01,  5.06it/s, loss=0.582, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  67%|██████▋   | 18/27 [00:03<00:01,  5.06it/s, loss=0.576, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  70%|███████   | 19/27 [00:03<00:01,  5.06it/s, loss=0.589, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 10:  74%|███████▍  | 20/27 [00:03<00:01,  5.06it/s, loss=0.589, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  78%|███████▊  | 21/27 [00:04<00:01,  5.06it/s, loss=0.585, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  81%|████████▏ | 22/27 [00:04<00:00,  5.06it/s, loss=0.581, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  85%|████████▌ | 23/27 [00:04<00:00,  5.06it/s, loss=0.582, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  89%|████████▉ | 24/27 [00:04<00:00,  5.06it/s, loss=0.576, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  93%|█████████▎| 25/27 [00:04<00:00,  5.06it/s, loss=0.579, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 10:  96%|█████████▋| 26/27 [00:05<00:00,  5.14it/s, loss=0.579, v_num=1, val_loss=0.558, val_ttr=0.000, val_ftr=0.000, val_acc=0.756, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.579, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:   4%|▎         | 1/27 [00:00<00:05,  5.07it/s, loss=0.584, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:   7%|▋         | 2/27 [00:00<00:04,  5.10it/s, loss=0.585, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  11%|█         | 3/27 [00:00<00:04,  5.08it/s, loss=0.584, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  15%|█▍        | 4/27 [00:00<00:04,  5.10it/s, loss=0.579, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  19%|█▊        | 5/27 [00:00<00:04,  5.10it/s, loss=0.575, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  22%|██▏       | 6/27 [00:01<00:04,  5.10it/s, loss=0.561, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  26%|██▌       | 7/27 [00:01<00:03,  5.10it/s, loss=0.562, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  30%|██▉       | 8/27 [00:01<00:03,  5.11it/s, loss=0.571, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  33%|███▎      | 9/27 [00:01<00:03,  5.11it/s, loss=0.574, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  37%|███▋      | 10/27 [00:01<00:03,  5.11it/s, loss=0.56, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  41%|████      | 11/27 [00:02<00:03,  5.11it/s, loss=0.563, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  44%|████▍     | 12/27 [00:02<00:02,  5.11it/s, loss=0.558, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  48%|████▊     | 13/27 [00:02<00:02,  5.12it/s, loss=0.567, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  52%|█████▏    | 14/27 [00:02<00:02,  5.11it/s, loss=0.562, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  56%|█████▌    | 15/27 [00:02<00:02,  5.11it/s, loss=0.566, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  59%|█████▉    | 16/27 [00:03<00:02,  5.11it/s, loss=0.571, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  63%|██████▎   | 17/27 [00:03<00:01,  5.11it/s, loss=0.57, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  67%|██████▋   | 18/27 [00:03<00:01,  5.00it/s, loss=0.568, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  70%|███████   | 19/27 [00:03<00:01,  5.01it/s, loss=0.579, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  74%|███████▍  | 20/27 [00:03<00:01,  5.02it/s, loss=0.578, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  78%|███████▊  | 21/27 [00:04<00:01,  5.02it/s, loss=0.576, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  81%|████████▏ | 22/27 [00:04<00:00,  5.03it/s, loss=0.578, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  85%|████████▌ | 23/27 [00:04<00:00,  5.03it/s, loss=0.571, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  89%|████████▉ | 24/27 [00:04<00:00,  5.04it/s, loss=0.575, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 11:  93%|█████████▎| 25/27 [00:04<00:00,  5.04it/s, loss=0.58, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 11:  96%|█████████▋| 26/27 [00:05<00:00,  5.11it/s, loss=0.58, v_num=1, val_loss=0.467, val_ttr=0.000, val_ftr=0.000, val_acc=0.829, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.58, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:   4%|▎         | 1/27 [00:00<00:05,  4.74it/s, loss=0.579, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:   7%|▋         | 2/27 [00:00<00:05,  4.82it/s, loss=0.57, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  11%|█         | 3/27 [00:00<00:04,  4.87it/s, loss=0.558, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  15%|█▍        | 4/27 [00:00<00:04,  4.94it/s, loss=0.559, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  19%|█▊        | 5/27 [00:01<00:04,  4.97it/s, loss=0.579, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  22%|██▏       | 6/27 [00:01<00:04,  4.98it/s, loss=0.581, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  26%|██▌       | 7/27 [00:01<00:04,  4.99it/s, loss=0.596, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  30%|██▉       | 8/27 [00:01<00:03,  5.00it/s, loss=0.6, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]  forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  33%|███▎      | 9/27 [00:01<00:03,  5.01it/s, loss=0.593, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  37%|███▋      | 10/27 [00:01<00:03,  5.02it/s, loss=0.589, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  41%|████      | 11/27 [00:02<00:03,  5.03it/s, loss=0.594, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  44%|████▍     | 12/27 [00:02<00:02,  5.03it/s, loss=0.595, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  48%|████▊     | 13/27 [00:02<00:02,  5.03it/s, loss=0.596, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  52%|█████▏    | 14/27 [00:02<00:02,  5.03it/s, loss=0.596, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  56%|█████▌    | 15/27 [00:02<00:02,  5.03it/s, loss=0.599, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  59%|█████▉    | 16/27 [00:03<00:02,  5.03it/s, loss=0.595, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  63%|██████▎   | 17/27 [00:03<00:01,  5.03it/s, loss=0.594, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  67%|██████▋   | 18/27 [00:03<00:01,  5.03it/s, loss=0.601, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  70%|███████   | 19/27 [00:03<00:01,  5.03it/s, loss=0.594, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  74%|███████▍  | 20/27 [00:03<00:01,  5.04it/s, loss=0.594, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  78%|███████▊  | 21/27 [00:04<00:01,  5.04it/s, loss=0.598, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  81%|████████▏ | 22/27 [00:04<00:00,  5.04it/s, loss=0.608, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  85%|████████▌ | 23/27 [00:04<00:00,  5.05it/s, loss=0.612, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  89%|████████▉ | 24/27 [00:04<00:00,  5.05it/s, loss=0.612, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 12:  93%|█████████▎| 25/27 [00:04<00:00,  5.05it/s, loss=0.602, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 12:  96%|█████████▋| 26/27 [00:05<00:00,  5.13it/s, loss=0.602, v_num=1, val_loss=0.509, val_ttr=0.000, val_ftr=0.000, val_acc=0.811, train_loss=0.581, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.602, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:   4%|▎         | 1/27 [00:00<00:05,  5.13it/s, loss=0.601, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:   7%|▋         | 2/27 [00:00<00:04,  5.16it/s, loss=0.6, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]  forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  11%|█         | 3/27 [00:00<00:04,  5.17it/s, loss=0.577, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  15%|█▍        | 4/27 [00:00<00:04,  5.16it/s, loss=0.573, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  19%|█▊        | 5/27 [00:00<00:04,  5.15it/s, loss=0.573, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  22%|██▏       | 6/27 [00:01<00:04,  5.14it/s, loss=0.566, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  26%|██▌       | 7/27 [00:01<00:03,  5.13it/s, loss=0.57, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  30%|██▉       | 8/27 [00:01<00:03,  5.12it/s, loss=0.572, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  33%|███▎      | 9/27 [00:01<00:03,  5.11it/s, loss=0.568, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  37%|███▋      | 10/27 [00:01<00:03,  5.10it/s, loss=0.565, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  41%|████      | 11/27 [00:02<00:03,  5.09it/s, loss=0.577, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  44%|████▍     | 12/27 [00:02<00:02,  5.08it/s, loss=0.57, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  48%|████▊     | 13/27 [00:02<00:02,  5.08it/s, loss=0.566, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  52%|█████▏    | 14/27 [00:02<00:02,  5.08it/s, loss=0.569, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  56%|█████▌    | 15/27 [00:02<00:02,  5.08it/s, loss=0.578, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  59%|█████▉    | 16/27 [00:03<00:02,  5.08it/s, loss=0.575, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  63%|██████▎   | 17/27 [00:03<00:01,  5.07it/s, loss=0.573, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  67%|██████▋   | 18/27 [00:03<00:01,  5.07it/s, loss=0.579, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  70%|███████   | 19/27 [00:03<00:01,  5.07it/s, loss=0.571, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  74%|███████▍  | 20/27 [00:03<00:01,  5.07it/s, loss=0.574, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  78%|███████▊  | 21/27 [00:04<00:01,  5.07it/s, loss=0.574, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  81%|████████▏ | 22/27 [00:04<00:00,  5.06it/s, loss=0.565, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  85%|████████▌ | 23/27 [00:04<00:00,  5.07it/s, loss=0.584, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  89%|████████▉ | 24/27 [00:04<00:00,  5.06it/s, loss=0.591, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 13:  93%|█████████▎| 25/27 [00:04<00:00,  5.07it/s, loss=0.591, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 13:  96%|█████████▋| 26/27 [00:05<00:00,  5.14it/s, loss=0.591, v_num=1, val_loss=0.606, val_ttr=0.000, val_ftr=0.000, val_acc=0.733, train_loss=0.591, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.591, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:   4%|▎         | 1/27 [00:00<00:05,  4.87it/s, loss=0.601, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:   7%|▋         | 2/27 [00:00<00:05,  4.94it/s, loss=0.599, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:  11%|█         | 3/27 [00:00<00:04,  4.96it/s, loss=0.596, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  15%|█▍        | 4/27 [00:00<00:04,  4.97it/s, loss=0.601, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:  19%|█▊        | 5/27 [00:01<00:04,  4.97it/s, loss=0.598, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  22%|██▏       | 6/27 [00:01<00:04,  4.98it/s, loss=0.587, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  26%|██▌       | 7/27 [00:01<00:03,  5.00it/s, loss=0.593, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  30%|██▉       | 8/27 [00:01<00:03,  5.02it/s, loss=0.598, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  33%|███▎      | 9/27 [00:01<00:03,  5.03it/s, loss=0.6, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]  forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  37%|███▋      | 10/27 [00:01<00:03,  5.04it/s, loss=0.595, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  41%|████      | 11/27 [00:02<00:03,  5.05it/s, loss=0.596, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  44%|████▍     | 12/27 [00:02<00:02,  5.06it/s, loss=0.595, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:  48%|████▊     | 13/27 [00:02<00:02,  5.06it/s, loss=0.59, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  52%|█████▏    | 14/27 [00:02<00:02,  5.07it/s, loss=0.593, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  56%|█████▌    | 15/27 [00:03<00:02,  4.94it/s, loss=0.592, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  59%|█████▉    | 16/27 [00:03<00:02,  4.95it/s, loss=0.602, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:  63%|██████▎   | 17/27 [00:03<00:02,  4.96it/s, loss=0.596, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  67%|██████▋   | 18/27 [00:03<00:01,  4.97it/s, loss=0.585, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:  70%|███████   | 19/27 [00:03<00:01,  4.98it/s, loss=0.586, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  74%|███████▍  | 20/27 [00:04<00:01,  4.99it/s, loss=0.586, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  78%|███████▊  | 21/27 [00:04<00:01,  4.99it/s, loss=0.57, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:  81%|████████▏ | 22/27 [00:04<00:00,  5.00it/s, loss=0.564, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:  85%|████████▌ | 23/27 [00:04<00:00,  5.01it/s, loss=0.57, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:  89%|████████▉ | 24/27 [00:04<00:00,  5.01it/s, loss=0.565, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 14:  93%|█████████▎| 25/27 [00:04<00:00,  5.02it/s, loss=0.561, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 14:  96%|█████████▋| 26/27 [00:05<00:00,  5.10it/s, loss=0.561, v_num=1, val_loss=0.527, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.561, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:   4%|▎         | 1/27 [00:00<00:05,  4.80it/s, loss=0.563, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:   7%|▋         | 2/27 [00:00<00:05,  4.87it/s, loss=0.562, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:  11%|█         | 3/27 [00:00<00:04,  4.91it/s, loss=0.55, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  15%|█▍        | 4/27 [00:00<00:04,  4.95it/s, loss=0.554, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:  19%|█▊        | 5/27 [00:01<00:04,  4.96it/s, loss=0.558, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  22%|██▏       | 6/27 [00:01<00:04,  4.97it/s, loss=0.556, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  26%|██▌       | 7/27 [00:01<00:04,  4.95it/s, loss=0.559, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  30%|██▉       | 8/27 [00:01<00:03,  4.97it/s, loss=0.564, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  33%|███▎      | 9/27 [00:01<00:03,  4.99it/s, loss=0.567, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  37%|███▋      | 10/27 [00:02<00:03,  5.00it/s, loss=0.566, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  41%|████      | 11/27 [00:02<00:03,  5.00it/s, loss=0.551, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:  44%|████▍     | 12/27 [00:02<00:02,  5.02it/s, loss=0.567, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  48%|████▊     | 13/27 [00:02<00:02,  5.02it/s, loss=0.573, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  52%|█████▏    | 14/27 [00:02<00:02,  5.03it/s, loss=0.57, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:  56%|█████▌    | 15/27 [00:02<00:02,  5.03it/s, loss=0.575, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  59%|█████▉    | 16/27 [00:03<00:02,  5.04it/s, loss=0.579, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  63%|██████▎   | 17/27 [00:03<00:01,  5.04it/s, loss=0.585, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  67%|██████▋   | 18/27 [00:03<00:01,  5.05it/s, loss=0.581, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  70%|███████   | 19/27 [00:03<00:01,  5.05it/s, loss=0.577, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:  74%|███████▍  | 20/27 [00:03<00:01,  5.06it/s, loss=0.581, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  78%|███████▊  | 21/27 [00:04<00:01,  5.07it/s, loss=0.576, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:  81%|████████▏ | 22/27 [00:04<00:00,  5.07it/s, loss=0.573, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:  85%|████████▌ | 23/27 [00:04<00:00,  5.07it/s, loss=0.58, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:  89%|████████▉ | 24/27 [00:04<00:00,  5.07it/s, loss=0.568, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 15:  93%|█████████▎| 25/27 [00:04<00:00,  5.07it/s, loss=0.562, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 15:  96%|█████████▋| 26/27 [00:05<00:00,  5.14it/s, loss=0.562, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.562, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:   4%|▎         | 1/27 [00:00<00:05,  4.83it/s, loss=0.572, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:   7%|▋         | 2/27 [00:00<00:05,  4.96it/s, loss=0.581, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 16:  11%|█         | 3/27 [00:00<00:04,  4.99it/s, loss=0.578, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  15%|█▍        | 4/27 [00:00<00:04,  5.01it/s, loss=0.577, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 16:  19%|█▊        | 5/27 [00:00<00:04,  5.02it/s, loss=0.577, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  22%|██▏       | 6/27 [00:01<00:04,  5.02it/s, loss=0.584, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  26%|██▌       | 7/27 [00:01<00:03,  5.03it/s, loss=0.581, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 16:  30%|██▉       | 8/27 [00:01<00:03,  5.04it/s, loss=0.58, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  33%|███▎      | 9/27 [00:01<00:03,  5.06it/s, loss=0.58, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  37%|███▋      | 10/27 [00:01<00:03,  5.07it/s, loss=0.571, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  41%|████      | 11/27 [00:02<00:03,  5.07it/s, loss=0.571, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 16:  44%|████▍     | 12/27 [00:02<00:02,  5.08it/s, loss=0.574, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 16:  48%|████▊     | 13/27 [00:02<00:02,  5.08it/s, loss=0.573, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  52%|█████▏    | 14/27 [00:02<00:02,  5.09it/s, loss=0.577, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  56%|█████▌    | 15/27 [00:02<00:02,  5.09it/s, loss=0.572, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  59%|█████▉    | 16/27 [00:03<00:02,  5.09it/s, loss=0.576, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  63%|██████▎   | 17/27 [00:03<00:01,  5.09it/s, loss=0.573, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  67%|██████▋   | 18/27 [00:03<00:01,  5.09it/s, loss=0.573, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 16:  70%|███████   | 19/27 [00:03<00:01,  5.09it/s, loss=0.589, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  74%|███████▍  | 20/27 [00:03<00:01,  5.09it/s, loss=0.591, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  78%|███████▊  | 21/27 [00:04<00:01,  5.09it/s, loss=0.58, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  81%|████████▏ | 22/27 [00:04<00:00,  5.09it/s, loss=0.564, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  85%|████████▌ | 23/27 [00:04<00:00,  5.09it/s, loss=0.563, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 16:  89%|████████▉ | 24/27 [00:04<00:00,  5.09it/s, loss=0.563, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 16:  93%|█████████▎| 25/27 [00:04<00:00,  5.08it/s, loss=0.568, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 16:  96%|█████████▋| 26/27 [00:05<00:00,  5.16it/s, loss=0.568, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.812, train_loss=0.570, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.568, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:   4%|▎         | 1/27 [00:00<00:05,  5.12it/s, loss=0.566, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:   7%|▋         | 2/27 [00:00<00:04,  5.10it/s, loss=0.565, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  11%|█         | 3/27 [00:00<00:05,  4.46it/s, loss=0.564, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  15%|█▍        | 4/27 [00:00<00:05,  4.60it/s, loss=0.564, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  19%|█▊        | 5/27 [00:01<00:04,  4.69it/s, loss=0.571, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  22%|██▏       | 6/27 [00:01<00:04,  4.76it/s, loss=0.575, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  26%|██▌       | 7/27 [00:01<00:04,  4.81it/s, loss=0.573, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  30%|██▉       | 8/27 [00:01<00:03,  4.84it/s, loss=0.58, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  33%|███▎      | 9/27 [00:01<00:03,  4.86it/s, loss=0.579, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  37%|███▋      | 10/27 [00:02<00:03,  4.86it/s, loss=0.588, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  41%|████      | 11/27 [00:02<00:03,  4.88it/s, loss=0.59, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  44%|████▍     | 12/27 [00:02<00:03,  4.88it/s, loss=0.591, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  48%|████▊     | 13/27 [00:02<00:02,  4.89it/s, loss=0.592, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  52%|█████▏    | 14/27 [00:02<00:02,  4.89it/s, loss=0.582, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  56%|█████▌    | 15/27 [00:03<00:02,  4.91it/s, loss=0.576, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  59%|█████▉    | 16/27 [00:03<00:02,  4.92it/s, loss=0.582, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  63%|██████▎   | 17/27 [00:03<00:02,  4.94it/s, loss=0.583, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  67%|██████▋   | 18/27 [00:03<00:01,  4.95it/s, loss=0.581, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  70%|███████   | 19/27 [00:03<00:01,  4.96it/s, loss=0.58, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  74%|███████▍  | 20/27 [00:04<00:01,  4.97it/s, loss=0.574, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  78%|███████▊  | 21/27 [00:04<00:01,  4.98it/s, loss=0.571, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  81%|████████▏ | 22/27 [00:04<00:01,  4.99it/s, loss=0.577, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  85%|████████▌ | 23/27 [00:04<00:00,  4.99it/s, loss=0.577, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 17:  89%|████████▉ | 24/27 [00:04<00:00,  4.99it/s, loss=0.578, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  93%|█████████▎| 25/27 [00:05<00:00,  4.99it/s, loss=0.572, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 17:  96%|█████████▋| 26/27 [00:05<00:00,  5.07it/s, loss=0.572, v_num=1, val_loss=0.545, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.572, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:   4%|▎         | 1/27 [00:00<00:05,  5.08it/s, loss=0.565, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:   7%|▋         | 2/27 [00:00<00:04,  5.12it/s, loss=0.566, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  11%|█         | 3/27 [00:00<00:04,  5.14it/s, loss=0.554, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  15%|█▍        | 4/27 [00:00<00:04,  5.14it/s, loss=0.55, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  19%|█▊        | 5/27 [00:00<00:04,  5.14it/s, loss=0.551, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  22%|██▏       | 6/27 [00:01<00:04,  5.15it/s, loss=0.548, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  26%|██▌       | 7/27 [00:01<00:03,  5.14it/s, loss=0.553, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  30%|██▉       | 8/27 [00:01<00:03,  5.14it/s, loss=0.557, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  33%|███▎      | 9/27 [00:01<00:03,  5.12it/s, loss=0.557, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  37%|███▋      | 10/27 [00:01<00:03,  5.13it/s, loss=0.557, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  41%|████      | 11/27 [00:02<00:03,  5.13it/s, loss=0.552, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  44%|████▍     | 12/27 [00:02<00:02,  5.13it/s, loss=0.555, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  48%|████▊     | 13/27 [00:02<00:02,  5.13it/s, loss=0.562, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  52%|█████▏    | 14/27 [00:02<00:02,  5.13it/s, loss=0.563, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  56%|█████▌    | 15/27 [00:02<00:02,  5.13it/s, loss=0.563, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  59%|█████▉    | 16/27 [00:03<00:02,  5.13it/s, loss=0.56, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  63%|██████▎   | 17/27 [00:03<00:01,  5.13it/s, loss=0.561, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  67%|██████▋   | 18/27 [00:03<00:01,  5.13it/s, loss=0.57, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  70%|███████   | 19/27 [00:03<00:01,  5.13it/s, loss=0.569, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  74%|███████▍  | 20/27 [00:03<00:01,  5.13it/s, loss=0.57, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  78%|███████▊  | 21/27 [00:04<00:01,  5.13it/s, loss=0.572, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  81%|████████▏ | 22/27 [00:04<00:00,  5.13it/s, loss=0.573, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  85%|████████▌ | 23/27 [00:04<00:00,  5.13it/s, loss=0.581, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 18:  89%|████████▉ | 24/27 [00:04<00:00,  5.13it/s, loss=0.583, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  93%|█████████▎| 25/27 [00:04<00:00,  5.12it/s, loss=0.581, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 18:  96%|█████████▋| 26/27 [00:05<00:00,  5.20it/s, loss=0.581, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.815, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.581, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:   4%|▎         | 1/27 [00:00<00:07,  3.48it/s, loss=0.58, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:   7%|▋         | 2/27 [00:00<00:06,  4.15it/s, loss=0.579, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  11%|█         | 3/27 [00:00<00:05,  4.44it/s, loss=0.578, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 19:  15%|█▍        | 4/27 [00:00<00:05,  4.59it/s, loss=0.577, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  19%|█▊        | 5/27 [00:01<00:04,  4.69it/s, loss=0.575, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 19:  22%|██▏       | 6/27 [00:01<00:04,  4.75it/s, loss=0.583, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  26%|██▌       | 7/27 [00:01<00:04,  4.80it/s, loss=0.578, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  30%|██▉       | 8/27 [00:01<00:03,  4.84it/s, loss=0.584, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  33%|███▎      | 9/27 [00:01<00:03,  4.87it/s, loss=0.585, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 19:  37%|███▋      | 10/27 [00:02<00:03,  4.89it/s, loss=0.588, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  41%|████      | 11/27 [00:02<00:03,  4.91it/s, loss=0.595, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  44%|████▍     | 12/27 [00:02<00:03,  4.93it/s, loss=0.59, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  48%|████▊     | 13/27 [00:02<00:02,  4.94it/s, loss=0.58, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  52%|█████▏    | 14/27 [00:02<00:02,  4.95it/s, loss=0.573, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 19:  56%|█████▌    | 15/27 [00:03<00:02,  4.97it/s, loss=0.576, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  59%|█████▉    | 16/27 [00:03<00:02,  4.97it/s, loss=0.573, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 19:  63%|██████▎   | 17/27 [00:03<00:02,  4.98it/s, loss=0.563, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 19:  67%|██████▋   | 18/27 [00:03<00:01,  4.99it/s, loss=0.568, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 19:  70%|███████   | 19/27 [00:03<00:01,  5.00it/s, loss=0.564, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 19:  74%|███████▍  | 20/27 [00:03<00:01,  5.00it/s, loss=0.564, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  78%|███████▊  | 21/27 [00:04<00:01,  5.01it/s, loss=0.566, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 19:  81%|████████▏ | 22/27 [00:04<00:00,  5.02it/s, loss=0.566, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  85%|████████▌ | 23/27 [00:04<00:00,  5.02it/s, loss=0.559, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  89%|████████▉ | 24/27 [00:04<00:00,  5.03it/s, loss=0.569, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  93%|█████████▎| 25/27 [00:04<00:00,  5.04it/s, loss=0.574, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 19:  96%|█████████▋| 26/27 [00:05<00:00,  5.12it/s, loss=0.574, v_num=1, val_loss=0.576, val_ttr=0.000, val_ftr=0.000, val_acc=0.739, train_loss=0.572, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.574, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:   4%|▎         | 1/27 [00:00<00:05,  4.95it/s, loss=0.564, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:   7%|▋         | 2/27 [00:00<00:04,  5.06it/s, loss=0.567, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  11%|█         | 3/27 [00:00<00:04,  5.11it/s, loss=0.559, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  15%|█▍        | 4/27 [00:00<00:04,  5.11it/s, loss=0.561, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  19%|█▊        | 5/27 [00:00<00:04,  5.11it/s, loss=0.556, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  22%|██▏       | 6/27 [00:01<00:04,  5.11it/s, loss=0.551, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  26%|██▌       | 7/27 [00:01<00:03,  5.11it/s, loss=0.556, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  30%|██▉       | 8/27 [00:01<00:03,  5.11it/s, loss=0.557, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  33%|███▎      | 9/27 [00:01<00:03,  5.12it/s, loss=0.569, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  37%|███▋      | 10/27 [00:01<00:03,  5.12it/s, loss=0.571, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  41%|████      | 11/27 [00:02<00:03,  5.13it/s, loss=0.576, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  44%|████▍     | 12/27 [00:02<00:02,  5.12it/s, loss=0.578, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  48%|████▊     | 13/27 [00:02<00:02,  5.12it/s, loss=0.574, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  52%|█████▏    | 14/27 [00:02<00:02,  5.12it/s, loss=0.586, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  56%|█████▌    | 15/27 [00:02<00:02,  5.12it/s, loss=0.58, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  59%|█████▉    | 16/27 [00:03<00:02,  5.12it/s, loss=0.583, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  63%|██████▎   | 17/27 [00:03<00:02,  5.00it/s, loss=0.584, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  67%|██████▋   | 18/27 [00:03<00:01,  5.00it/s, loss=0.592, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  70%|███████   | 19/27 [00:03<00:01,  5.01it/s, loss=0.581, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  74%|███████▍  | 20/27 [00:03<00:01,  5.01it/s, loss=0.579, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  78%|███████▊  | 21/27 [00:04<00:01,  5.02it/s, loss=0.585, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  81%|████████▏ | 22/27 [00:04<00:00,  5.02it/s, loss=0.59, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  85%|████████▌ | 23/27 [00:04<00:00,  5.03it/s, loss=0.587, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  89%|████████▉ | 24/27 [00:04<00:00,  5.03it/s, loss=0.586, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 20:  93%|█████████▎| 25/27 [00:04<00:00,  5.04it/s, loss=0.578, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 20:  96%|█████████▋| 26/27 [00:05<00:00,  5.11it/s, loss=0.578, v_num=1, val_loss=0.533, val_ttr=0.000, val_ftr=0.000, val_acc=0.776, train_loss=0.569, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.578, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:   4%|▎         | 1/27 [00:00<00:05,  5.07it/s, loss=0.578, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:   7%|▋         | 2/27 [00:00<00:04,  5.10it/s, loss=0.574, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  11%|█         | 3/27 [00:00<00:04,  5.11it/s, loss=0.576, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  15%|█▍        | 4/27 [00:00<00:04,  5.12it/s, loss=0.564, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  19%|█▊        | 5/27 [00:00<00:04,  5.12it/s, loss=0.562, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  22%|██▏       | 6/27 [00:01<00:04,  5.10it/s, loss=0.565, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  26%|██▌       | 7/27 [00:01<00:03,  5.10it/s, loss=0.569, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  30%|██▉       | 8/27 [00:01<00:03,  5.10it/s, loss=0.563, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  33%|███▎      | 9/27 [00:01<00:03,  5.10it/s, loss=0.553, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  37%|███▋      | 10/27 [00:01<00:03,  5.10it/s, loss=0.562, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  41%|████      | 11/27 [00:02<00:03,  5.09it/s, loss=0.557, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  44%|████▍     | 12/27 [00:02<00:02,  5.09it/s, loss=0.556, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  48%|████▊     | 13/27 [00:02<00:02,  5.10it/s, loss=0.554, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  52%|█████▏    | 14/27 [00:02<00:02,  5.11it/s, loss=0.559, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  56%|█████▌    | 15/27 [00:02<00:02,  5.11it/s, loss=0.57, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  59%|█████▉    | 16/27 [00:03<00:02,  5.12it/s, loss=0.571, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  63%|██████▎   | 17/27 [00:03<00:01,  5.11it/s, loss=0.567, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  67%|██████▋   | 18/27 [00:03<00:01,  5.12it/s, loss=0.569, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  70%|███████   | 19/27 [00:03<00:01,  5.12it/s, loss=0.569, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  74%|███████▍  | 20/27 [00:03<00:01,  5.12it/s, loss=0.582, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  78%|███████▊  | 21/27 [00:04<00:01,  5.12it/s, loss=0.58, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  81%|████████▏ | 22/27 [00:04<00:00,  5.11it/s, loss=0.582, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 21:  85%|████████▌ | 23/27 [00:04<00:00,  5.11it/s, loss=0.581, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  89%|████████▉ | 24/27 [00:04<00:00,  5.11it/s, loss=0.586, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  93%|█████████▎| 25/27 [00:04<00:00,  5.12it/s, loss=0.581, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 21:  96%|█████████▋| 26/27 [00:05<00:00,  5.19it/s, loss=0.581, v_num=1, val_loss=0.504, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.581, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:   4%|▎         | 1/27 [00:00<00:05,  5.07it/s, loss=0.572, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:   7%|▋         | 2/27 [00:00<00:04,  5.16it/s, loss=0.572, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  11%|█         | 3/27 [00:00<00:04,  5.14it/s, loss=0.574, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  15%|█▍        | 4/27 [00:00<00:04,  5.12it/s, loss=0.58, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  19%|█▊        | 5/27 [00:00<00:04,  5.13it/s, loss=0.574, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  22%|██▏       | 6/27 [00:01<00:04,  5.13it/s, loss=0.582, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  26%|██▌       | 7/27 [00:01<00:03,  5.11it/s, loss=0.586, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  30%|██▉       | 8/27 [00:01<00:03,  5.11it/s, loss=0.579, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  33%|███▎      | 9/27 [00:01<00:03,  5.11it/s, loss=0.582, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  37%|███▋      | 10/27 [00:01<00:03,  5.12it/s, loss=0.566, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  41%|████      | 11/27 [00:02<00:03,  5.12it/s, loss=0.559, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  44%|████▍     | 12/27 [00:02<00:02,  5.12it/s, loss=0.561, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  48%|████▊     | 13/27 [00:02<00:02,  5.13it/s, loss=0.562, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  52%|█████▏    | 14/27 [00:02<00:02,  5.13it/s, loss=0.558, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  56%|█████▌    | 15/27 [00:02<00:02,  5.13it/s, loss=0.555, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  59%|█████▉    | 16/27 [00:03<00:02,  5.13it/s, loss=0.558, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  63%|██████▎   | 17/27 [00:03<00:01,  5.14it/s, loss=0.554, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  67%|██████▋   | 18/27 [00:03<00:01,  5.14it/s, loss=0.553, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  70%|███████   | 19/27 [00:03<00:01,  5.14it/s, loss=0.555, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  74%|███████▍  | 20/27 [00:03<00:01,  5.14it/s, loss=0.562, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  78%|███████▊  | 21/27 [00:04<00:01,  5.14it/s, loss=0.561, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  81%|████████▏ | 22/27 [00:04<00:00,  5.15it/s, loss=0.569, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  85%|████████▌ | 23/27 [00:04<00:00,  5.14it/s, loss=0.576, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 22:  89%|████████▉ | 24/27 [00:04<00:00,  5.14it/s, loss=0.577, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  93%|█████████▎| 25/27 [00:04<00:00,  5.14it/s, loss=0.578, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 22:  96%|█████████▋| 26/27 [00:04<00:00,  5.21it/s, loss=0.578, v_num=1, val_loss=0.525, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.578, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:   4%|▎         | 1/27 [00:00<00:05,  5.02it/s, loss=0.58, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:   7%|▋         | 2/27 [00:00<00:04,  5.10it/s, loss=0.582, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:  11%|█         | 3/27 [00:00<00:04,  5.12it/s, loss=0.585, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  15%|█▍        | 4/27 [00:00<00:04,  5.13it/s, loss=0.58, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:  19%|█▊        | 5/27 [00:00<00:04,  5.14it/s, loss=0.588, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  22%|██▏       | 6/27 [00:01<00:04,  5.13it/s, loss=0.598, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:  26%|██▌       | 7/27 [00:01<00:03,  5.13it/s, loss=0.6, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]  forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:  30%|██▉       | 8/27 [00:01<00:03,  5.14it/s, loss=0.597, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  33%|███▎      | 9/27 [00:01<00:03,  5.14it/s, loss=0.596, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  37%|███▋      | 10/27 [00:01<00:03,  5.14it/s, loss=0.597, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  41%|████      | 11/27 [00:02<00:03,  5.14it/s, loss=0.593, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:  44%|████▍     | 12/27 [00:02<00:02,  5.14it/s, loss=0.587, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  48%|████▊     | 13/27 [00:02<00:02,  5.14it/s, loss=0.586, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  52%|█████▏    | 14/27 [00:02<00:02,  5.00it/s, loss=0.59, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  56%|█████▌    | 15/27 [00:02<00:02,  5.01it/s, loss=0.587, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  59%|█████▉    | 16/27 [00:03<00:02,  5.02it/s, loss=0.594, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:  63%|██████▎   | 17/27 [00:03<00:01,  5.02it/s, loss=0.596, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  67%|██████▋   | 18/27 [00:03<00:01,  5.03it/s, loss=0.592, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  70%|███████   | 19/27 [00:03<00:01,  5.04it/s, loss=0.591, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  74%|███████▍  | 20/27 [00:03<00:01,  5.04it/s, loss=0.591, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  78%|███████▊  | 21/27 [00:04<00:01,  5.05it/s, loss=0.573, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:  81%|████████▏ | 22/27 [00:04<00:00,  5.05it/s, loss=0.571, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  85%|████████▌ | 23/27 [00:04<00:00,  5.06it/s, loss=0.575, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 23:  89%|████████▉ | 24/27 [00:04<00:00,  5.07it/s, loss=0.578, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  93%|█████████▎| 25/27 [00:04<00:00,  5.07it/s, loss=0.57, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 23:  96%|█████████▋| 26/27 [00:05<00:00,  5.15it/s, loss=0.57, v_num=1, val_loss=0.553, val_ttr=0.000, val_ftr=0.000, val_acc=0.764, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.747]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.57, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 24:   4%|▎         | 1/27 [00:00<00:04,  5.23it/s, loss=0.567, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:   7%|▋         | 2/27 [00:00<00:04,  5.25it/s, loss=0.559, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  11%|█         | 3/27 [00:00<00:04,  5.24it/s, loss=0.561, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 24:  15%|█▍        | 4/27 [00:00<00:04,  5.25it/s, loss=0.571, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  19%|█▊        | 5/27 [00:00<00:04,  5.23it/s, loss=0.567, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  22%|██▏       | 6/27 [00:01<00:04,  5.24it/s, loss=0.566, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  26%|██▌       | 7/27 [00:01<00:03,  5.23it/s, loss=0.573, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  30%|██▉       | 8/27 [00:01<00:03,  5.23it/s, loss=0.581, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 24:  33%|███▎      | 9/27 [00:01<00:03,  5.22it/s, loss=0.58, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 24:  37%|███▋      | 10/27 [00:01<00:03,  5.22it/s, loss=0.582, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  41%|████      | 11/27 [00:02<00:03,  5.21it/s, loss=0.579, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 24:  44%|████▍     | 12/27 [00:02<00:02,  5.22it/s, loss=0.566, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  48%|████▊     | 13/27 [00:02<00:02,  5.22it/s, loss=0.568, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  52%|█████▏    | 14/27 [00:02<00:02,  5.23it/s, loss=0.576, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  56%|█████▌    | 15/27 [00:02<00:02,  5.23it/s, loss=0.572, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  59%|█████▉    | 16/27 [00:03<00:02,  5.23it/s, loss=0.578, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  63%|██████▎   | 17/27 [00:03<00:01,  5.23it/s, loss=0.576, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  67%|██████▋   | 18/27 [00:03<00:01,  5.23it/s, loss=0.574, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 24:  70%|███████   | 19/27 [00:03<00:01,  5.23it/s, loss=0.571, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  74%|███████▍  | 20/27 [00:03<00:01,  5.22it/s, loss=0.574, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  78%|███████▊  | 21/27 [00:04<00:01,  5.22it/s, loss=0.572, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  81%|████████▏ | 22/27 [00:04<00:00,  5.22it/s, loss=0.571, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  85%|████████▌ | 23/27 [00:04<00:00,  5.22it/s, loss=0.579, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  89%|████████▉ | 24/27 [00:04<00:00,  5.22it/s, loss=0.579, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 24:  93%|█████████▎| 25/27 [00:04<00:00,  5.22it/s, loss=0.58, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 24:  96%|█████████▋| 26/27 [00:04<00:00,  5.29it/s, loss=0.58, v_num=1, val_loss=0.540, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.582, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.58, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:   4%|▎         | 1/27 [00:00<00:05,  4.99it/s, loss=0.585, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:   7%|▋         | 2/27 [00:00<00:04,  5.10it/s, loss=0.579, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  11%|█         | 3/27 [00:00<00:04,  5.14it/s, loss=0.579, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 25:  15%|█▍        | 4/27 [00:00<00:04,  5.16it/s, loss=0.57, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  19%|█▊        | 5/27 [00:00<00:04,  5.18it/s, loss=0.572, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 25:  22%|██▏       | 6/27 [00:01<00:04,  5.18it/s, loss=0.576, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  26%|██▌       | 7/27 [00:01<00:03,  5.16it/s, loss=0.576, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  30%|██▉       | 8/27 [00:01<00:03,  5.17it/s, loss=0.575, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 25:  33%|███▎      | 9/27 [00:01<00:03,  5.17it/s, loss=0.568, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 25:  37%|███▋      | 10/27 [00:01<00:03,  5.17it/s, loss=0.574, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  41%|████      | 11/27 [00:02<00:03,  5.17it/s, loss=0.577, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 25:  44%|████▍     | 12/27 [00:02<00:02,  5.16it/s, loss=0.57, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 25:  48%|████▊     | 13/27 [00:02<00:02,  5.16it/s, loss=0.572, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  52%|█████▏    | 14/27 [00:02<00:02,  5.16it/s, loss=0.569, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  56%|█████▌    | 15/27 [00:02<00:02,  5.15it/s, loss=0.571, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 25:  59%|█████▉    | 16/27 [00:03<00:02,  5.15it/s, loss=0.576, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  63%|██████▎   | 17/27 [00:03<00:01,  5.14it/s, loss=0.579, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 25:  67%|██████▋   | 18/27 [00:03<00:01,  5.14it/s, loss=0.573, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  70%|███████   | 19/27 [00:03<00:01,  5.14it/s, loss=0.564, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  74%|███████▍  | 20/27 [00:03<00:01,  5.13it/s, loss=0.565, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  78%|███████▊  | 21/27 [00:04<00:01,  5.13it/s, loss=0.571, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  81%|████████▏ | 22/27 [00:04<00:00,  5.13it/s, loss=0.579, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 25:  85%|████████▌ | 23/27 [00:04<00:00,  5.13it/s, loss=0.571, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  89%|████████▉ | 24/27 [00:04<00:00,  5.13it/s, loss=0.582, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  93%|█████████▎| 25/27 [00:04<00:00,  5.13it/s, loss=0.572, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 25:  96%|█████████▋| 26/27 [00:04<00:00,  5.21it/s, loss=0.572, v_num=1, val_loss=0.510, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.577, train_ttr=0.000, train_ftr=0.000, train_acc=0.742]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.572, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:   4%|▎         | 1/27 [00:00<00:05,  5.04it/s, loss=0.568, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:   7%|▋         | 2/27 [00:00<00:05,  4.20it/s, loss=0.576, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  11%|█         | 3/27 [00:00<00:05,  4.48it/s, loss=0.578, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  15%|█▍        | 4/27 [00:00<00:04,  4.61it/s, loss=0.579, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  19%|█▊        | 5/27 [00:01<00:04,  4.71it/s, loss=0.575, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  22%|██▏       | 6/27 [00:01<00:04,  4.78it/s, loss=0.579, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  26%|██▌       | 7/27 [00:01<00:04,  4.82it/s, loss=0.581, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  30%|██▉       | 8/27 [00:01<00:03,  4.87it/s, loss=0.577, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  33%|███▎      | 9/27 [00:01<00:03,  4.90it/s, loss=0.58, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  37%|███▋      | 10/27 [00:02<00:03,  4.92it/s, loss=0.584, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  41%|████      | 11/27 [00:02<00:03,  4.94it/s, loss=0.581, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  44%|████▍     | 12/27 [00:02<00:03,  4.95it/s, loss=0.579, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  48%|████▊     | 13/27 [00:02<00:02,  4.96it/s, loss=0.582, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  52%|█████▏    | 14/27 [00:02<00:02,  4.97it/s, loss=0.579, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  56%|█████▌    | 15/27 [00:03<00:02,  4.98it/s, loss=0.573, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  59%|█████▉    | 16/27 [00:03<00:02,  4.99it/s, loss=0.575, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  63%|██████▎   | 17/27 [00:03<00:02,  5.00it/s, loss=0.575, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  67%|██████▋   | 18/27 [00:03<00:01,  5.01it/s, loss=0.582, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  70%|███████   | 19/27 [00:03<00:01,  5.01it/s, loss=0.577, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  74%|███████▍  | 20/27 [00:03<00:01,  5.02it/s, loss=0.584, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  78%|███████▊  | 21/27 [00:04<00:01,  5.02it/s, loss=0.585, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  81%|████████▏ | 22/27 [00:04<00:00,  5.03it/s, loss=0.577, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  85%|████████▌ | 23/27 [00:04<00:00,  5.03it/s, loss=0.575, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 26:  89%|████████▉ | 24/27 [00:04<00:00,  5.04it/s, loss=0.566, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  93%|█████████▎| 25/27 [00:04<00:00,  5.04it/s, loss=0.567, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 26:  96%|█████████▋| 26/27 [00:05<00:00,  5.12it/s, loss=0.567, v_num=1, val_loss=0.516, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.567, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:   4%|▎         | 1/27 [00:00<00:05,  5.11it/s, loss=0.563, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:   7%|▋         | 2/27 [00:00<00:04,  5.17it/s, loss=0.562, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 27:  11%|█         | 3/27 [00:00<00:04,  5.17it/s, loss=0.563, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  15%|█▍        | 4/27 [00:00<00:04,  5.20it/s, loss=0.555, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  19%|█▊        | 5/27 [00:00<00:04,  5.21it/s, loss=0.554, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  22%|██▏       | 6/27 [00:01<00:04,  5.20it/s, loss=0.558, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  26%|██▌       | 7/27 [00:01<00:03,  5.19it/s, loss=0.567, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  30%|██▉       | 8/27 [00:01<00:03,  5.19it/s, loss=0.564, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 27:  33%|███▎      | 9/27 [00:01<00:03,  5.18it/s, loss=0.571, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  37%|███▋      | 10/27 [00:01<00:03,  5.18it/s, loss=0.576, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  41%|████      | 11/27 [00:02<00:03,  5.18it/s, loss=0.571, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  44%|████▍     | 12/27 [00:02<00:02,  5.17it/s, loss=0.566, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  48%|████▊     | 13/27 [00:02<00:02,  5.18it/s, loss=0.562, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  52%|█████▏    | 14/27 [00:02<00:02,  5.17it/s, loss=0.556, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  56%|█████▌    | 15/27 [00:02<00:02,  5.17it/s, loss=0.549, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  59%|█████▉    | 16/27 [00:03<00:02,  5.17it/s, loss=0.555, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  63%|██████▎   | 17/27 [00:03<00:01,  5.17it/s, loss=0.552, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  67%|██████▋   | 18/27 [00:03<00:01,  5.16it/s, loss=0.549, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  70%|███████   | 19/27 [00:03<00:01,  5.17it/s, loss=0.553, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  74%|███████▍  | 20/27 [00:03<00:01,  5.17it/s, loss=0.559, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  78%|███████▊  | 21/27 [00:04<00:01,  5.17it/s, loss=0.562, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  81%|████████▏ | 22/27 [00:04<00:00,  5.16it/s, loss=0.567, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  85%|████████▌ | 23/27 [00:04<00:00,  5.16it/s, loss=0.569, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  89%|████████▉ | 24/27 [00:04<00:00,  5.16it/s, loss=0.581, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  93%|█████████▎| 25/27 [00:04<00:00,  5.16it/s, loss=0.588, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 27:  96%|█████████▋| 26/27 [00:04<00:00,  5.24it/s, loss=0.588, v_num=1, val_loss=0.513, val_ttr=0.000, val_ftr=0.000, val_acc=0.798, train_loss=0.574, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.588, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:   4%|▎         | 1/27 [00:00<00:05,  5.16it/s, loss=0.589, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:   7%|▋         | 2/27 [00:00<00:04,  5.15it/s, loss=0.58, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  11%|█         | 3/27 [00:00<00:04,  5.16it/s, loss=0.576, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  15%|█▍        | 4/27 [00:00<00:04,  5.16it/s, loss=0.574, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  19%|█▊        | 5/27 [00:00<00:04,  5.14it/s, loss=0.577, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  22%|██▏       | 6/27 [00:01<00:04,  5.14it/s, loss=0.576, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  26%|██▌       | 7/27 [00:01<00:03,  5.14it/s, loss=0.574, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  30%|██▉       | 8/27 [00:01<00:03,  5.16it/s, loss=0.572, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  33%|███▎      | 9/27 [00:01<00:03,  5.17it/s, loss=0.585, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  37%|███▋      | 10/27 [00:01<00:03,  5.18it/s, loss=0.586, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  41%|████      | 11/27 [00:02<00:03,  5.18it/s, loss=0.578, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  44%|████▍     | 12/27 [00:02<00:02,  5.16it/s, loss=0.589, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  48%|████▊     | 13/27 [00:02<00:02,  5.15it/s, loss=0.595, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  52%|█████▏    | 14/27 [00:02<00:02,  5.16it/s, loss=0.595, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  56%|█████▌    | 15/27 [00:02<00:02,  5.16it/s, loss=0.587, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  59%|█████▉    | 16/27 [00:03<00:02,  5.16it/s, loss=0.591, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  63%|██████▎   | 17/27 [00:03<00:01,  5.16it/s, loss=0.596, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  67%|██████▋   | 18/27 [00:03<00:01,  5.16it/s, loss=0.592, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  70%|███████   | 19/27 [00:03<00:01,  5.16it/s, loss=0.583, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  74%|███████▍  | 20/27 [00:03<00:01,  5.15it/s, loss=0.573, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  78%|███████▊  | 21/27 [00:04<00:01,  5.15it/s, loss=0.576, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  81%|████████▏ | 22/27 [00:04<00:00,  5.14it/s, loss=0.577, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  85%|████████▌ | 23/27 [00:04<00:00,  5.14it/s, loss=0.579, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  89%|████████▉ | 24/27 [00:04<00:00,  5.13it/s, loss=0.58, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 28:  93%|█████████▎| 25/27 [00:04<00:00,  5.13it/s, loss=0.585, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 28:  96%|█████████▋| 26/27 [00:04<00:00,  5.20it/s, loss=0.585, v_num=1, val_loss=0.519, val_ttr=0.000, val_ftr=0.000, val_acc=0.795, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.585, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:   4%|▎         | 1/27 [00:00<00:05,  5.07it/s, loss=0.586, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:   7%|▋         | 2/27 [00:00<00:04,  5.04it/s, loss=0.591, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  11%|█         | 3/27 [00:00<00:04,  5.09it/s, loss=0.592, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  15%|█▍        | 4/27 [00:00<00:04,  5.11it/s, loss=0.583, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  19%|█▊        | 5/27 [00:00<00:04,  5.13it/s, loss=0.588, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  22%|██▏       | 6/27 [00:01<00:04,  5.15it/s, loss=0.6, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]  forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  26%|██▌       | 7/27 [00:01<00:03,  5.14it/s, loss=0.59, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  30%|██▉       | 8/27 [00:01<00:03,  5.15it/s, loss=0.586, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  33%|███▎      | 9/27 [00:01<00:03,  5.17it/s, loss=0.591, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  37%|███▋      | 10/27 [00:01<00:03,  5.17it/s, loss=0.593, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  41%|████      | 11/27 [00:02<00:03,  5.17it/s, loss=0.585, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  44%|████▍     | 12/27 [00:02<00:02,  5.16it/s, loss=0.579, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  48%|████▊     | 13/27 [00:02<00:02,  5.15it/s, loss=0.577, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  52%|█████▏    | 14/27 [00:02<00:02,  5.15it/s, loss=0.581, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  56%|█████▌    | 15/27 [00:02<00:02,  5.15it/s, loss=0.58, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  59%|█████▉    | 16/27 [00:03<00:02,  5.03it/s, loss=0.569, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  63%|██████▎   | 17/27 [00:03<00:01,  5.04it/s, loss=0.579, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  67%|██████▋   | 18/27 [00:03<00:01,  5.04it/s, loss=0.577, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  70%|███████   | 19/27 [00:03<00:01,  5.04it/s, loss=0.587, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  74%|███████▍  | 20/27 [00:03<00:01,  5.05it/s, loss=0.583, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  78%|███████▊  | 21/27 [00:04<00:01,  5.05it/s, loss=0.58, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  81%|████████▏ | 22/27 [00:04<00:00,  5.06it/s, loss=0.578, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  85%|████████▌ | 23/27 [00:04<00:00,  5.07it/s, loss=0.579, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 29:  89%|████████▉ | 24/27 [00:04<00:00,  5.08it/s, loss=0.578, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  93%|█████████▎| 25/27 [00:04<00:00,  5.08it/s, loss=0.571, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 29:  96%|█████████▋| 26/27 [00:05<00:00,  5.16it/s, loss=0.571, v_num=1, val_loss=0.505, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.741]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.571, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:   4%|▎         | 1/27 [00:00<00:05,  5.07it/s, loss=0.561, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:   7%|▋         | 2/27 [00:00<00:04,  5.11it/s, loss=0.562, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  11%|█         | 3/27 [00:00<00:04,  5.13it/s, loss=0.565, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  15%|█▍        | 4/27 [00:00<00:04,  5.15it/s, loss=0.557, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  19%|█▊        | 5/27 [00:00<00:04,  5.16it/s, loss=0.548, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  22%|██▏       | 6/27 [00:01<00:04,  5.17it/s, loss=0.547, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  26%|██▌       | 7/27 [00:01<00:03,  5.17it/s, loss=0.556, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  30%|██▉       | 8/27 [00:01<00:03,  5.17it/s, loss=0.571, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  33%|███▎      | 9/27 [00:01<00:03,  5.17it/s, loss=0.574, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  37%|███▋      | 10/27 [00:01<00:03,  5.17it/s, loss=0.576, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  41%|████      | 11/27 [00:02<00:03,  5.17it/s, loss=0.588, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  44%|████▍     | 12/27 [00:02<00:02,  5.16it/s, loss=0.574, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  48%|████▊     | 13/27 [00:02<00:02,  5.16it/s, loss=0.579, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  52%|█████▏    | 14/27 [00:02<00:02,  5.17it/s, loss=0.568, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  56%|█████▌    | 15/27 [00:02<00:02,  5.16it/s, loss=0.57, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  59%|█████▉    | 16/27 [00:03<00:02,  5.15it/s, loss=0.57, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  63%|██████▎   | 17/27 [00:03<00:01,  5.15it/s, loss=0.569, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  67%|██████▋   | 18/27 [00:03<00:01,  5.14it/s, loss=0.563, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  70%|███████   | 19/27 [00:03<00:01,  5.14it/s, loss=0.566, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  74%|███████▍  | 20/27 [00:03<00:01,  5.14it/s, loss=0.57, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  78%|███████▊  | 21/27 [00:04<00:01,  5.13it/s, loss=0.577, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  81%|████████▏ | 22/27 [00:04<00:00,  5.13it/s, loss=0.579, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  85%|████████▌ | 23/27 [00:04<00:00,  5.13it/s, loss=0.574, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  89%|████████▉ | 24/27 [00:04<00:00,  5.13it/s, loss=0.581, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 30:  93%|█████████▎| 25/27 [00:04<00:00,  5.13it/s, loss=0.591, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 30:  96%|█████████▋| 26/27 [00:05<00:00,  5.20it/s, loss=0.591, v_num=1, val_loss=0.534, val_ttr=0.000, val_ftr=0.000, val_acc=0.780, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.591, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:   4%|▎         | 1/27 [00:00<00:05,  4.74it/s, loss=0.603, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:   7%|▋         | 2/27 [00:00<00:05,  4.88it/s, loss=0.593, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 31:  11%|█         | 3/27 [00:00<00:04,  4.96it/s, loss=0.589, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 31:  15%|█▍        | 4/27 [00:00<00:04,  4.98it/s, loss=0.573, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  19%|█▊        | 5/27 [00:00<00:04,  5.00it/s, loss=0.574, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  22%|██▏       | 6/27 [00:01<00:04,  5.00it/s, loss=0.568, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  26%|██▌       | 7/27 [00:01<00:03,  5.02it/s, loss=0.576, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  30%|██▉       | 8/27 [00:01<00:03,  5.04it/s, loss=0.57, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  33%|███▎      | 9/27 [00:01<00:03,  5.05it/s, loss=0.566, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  37%|███▋      | 10/27 [00:01<00:03,  5.05it/s, loss=0.567, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 31:  41%|████      | 11/27 [00:02<00:03,  5.06it/s, loss=0.557, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  44%|████▍     | 12/27 [00:02<00:02,  5.05it/s, loss=0.562, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  48%|████▊     | 13/27 [00:02<00:02,  5.06it/s, loss=0.57, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  52%|█████▏    | 14/27 [00:02<00:02,  5.07it/s, loss=0.575, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  56%|█████▌    | 15/27 [00:02<00:02,  5.07it/s, loss=0.578, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  59%|█████▉    | 16/27 [00:03<00:02,  5.07it/s, loss=0.574, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  63%|██████▎   | 17/27 [00:03<00:01,  5.08it/s, loss=0.573, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  67%|██████▋   | 18/27 [00:03<00:01,  5.08it/s, loss=0.578, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  70%|███████   | 19/27 [00:03<00:01,  5.09it/s, loss=0.579, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 31:  74%|███████▍  | 20/27 [00:03<00:01,  5.09it/s, loss=0.575, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  78%|███████▊  | 21/27 [00:04<00:01,  5.09it/s, loss=0.568, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  81%|████████▏ | 22/27 [00:04<00:00,  5.09it/s, loss=0.568, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 31:  85%|████████▌ | 23/27 [00:04<00:00,  5.10it/s, loss=0.559, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  89%|████████▉ | 24/27 [00:04<00:00,  5.10it/s, loss=0.572, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 31:  93%|█████████▎| 25/27 [00:04<00:00,  5.10it/s, loss=0.57, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 31:  96%|█████████▋| 26/27 [00:05<00:00,  5.17it/s, loss=0.57, v_num=1, val_loss=0.485, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.745]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 32:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.57, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:   4%|▎         | 1/27 [00:00<00:05,  5.05it/s, loss=0.57, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:   7%|▋         | 2/27 [00:00<00:04,  5.11it/s, loss=0.57, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  11%|█         | 3/27 [00:00<00:04,  5.13it/s, loss=0.568, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  15%|█▍        | 4/27 [00:00<00:04,  5.11it/s, loss=0.576, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  19%|█▊        | 5/27 [00:00<00:04,  5.11it/s, loss=0.569, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  22%|██▏       | 6/27 [00:01<00:04,  5.10it/s, loss=0.591, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 32:  26%|██▌       | 7/27 [00:01<00:03,  5.11it/s, loss=0.579, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  30%|██▉       | 8/27 [00:01<00:03,  5.11it/s, loss=0.577, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  33%|███▎      | 9/27 [00:01<00:03,  5.10it/s, loss=0.573, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  37%|███▋      | 10/27 [00:01<00:03,  5.10it/s, loss=0.561, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 32:  41%|████      | 11/27 [00:02<00:03,  5.10it/s, loss=0.557, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  44%|████▍     | 12/27 [00:02<00:02,  5.10it/s, loss=0.57, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  48%|████▊     | 13/27 [00:02<00:02,  4.95it/s, loss=0.563, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  52%|█████▏    | 14/27 [00:02<00:02,  4.96it/s, loss=0.549, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  56%|█████▌    | 15/27 [00:03<00:02,  4.97it/s, loss=0.548, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 32:  59%|█████▉    | 16/27 [00:03<00:02,  4.98it/s, loss=0.548, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 32:  63%|██████▎   | 17/27 [00:03<00:02,  4.99it/s, loss=0.555, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 32:  67%|██████▋   | 18/27 [00:03<00:01,  5.00it/s, loss=0.553, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  70%|███████   | 19/27 [00:03<00:01,  5.01it/s, loss=0.557, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  74%|███████▍  | 20/27 [00:03<00:01,  5.01it/s, loss=0.563, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 32:  78%|███████▊  | 21/27 [00:04<00:01,  5.02it/s, loss=0.568, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  81%|████████▏ | 22/27 [00:04<00:00,  5.02it/s, loss=0.567, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  85%|████████▌ | 23/27 [00:04<00:00,  5.03it/s, loss=0.575, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 32:  89%|████████▉ | 24/27 [00:04<00:00,  5.03it/s, loss=0.572, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  93%|█████████▎| 25/27 [00:04<00:00,  5.03it/s, loss=0.577, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 32:  96%|█████████▋| 26/27 [00:05<00:00,  5.11it/s, loss=0.577, v_num=1, val_loss=0.547, val_ttr=0.000, val_ftr=0.000, val_acc=0.765, train_loss=0.571, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.577, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:   4%|▎         | 1/27 [00:00<00:05,  4.71it/s, loss=0.567, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:   7%|▋         | 2/27 [00:00<00:05,  4.82it/s, loss=0.578, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:  11%|█         | 3/27 [00:00<00:04,  4.93it/s, loss=0.583, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  15%|█▍        | 4/27 [00:00<00:04,  5.00it/s, loss=0.585, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:  19%|█▊        | 5/27 [00:00<00:04,  5.03it/s, loss=0.595, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:  22%|██▏       | 6/27 [00:01<00:04,  5.06it/s, loss=0.596, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:  26%|██▌       | 7/27 [00:01<00:03,  5.07it/s, loss=0.585, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:  30%|██▉       | 8/27 [00:01<00:03,  5.07it/s, loss=0.589, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  33%|███▎      | 9/27 [00:01<00:03,  5.07it/s, loss=0.598, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:  37%|███▋      | 10/27 [00:01<00:03,  5.06it/s, loss=0.596, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  41%|████      | 11/27 [00:02<00:03,  5.06it/s, loss=0.597, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:  44%|████▍     | 12/27 [00:02<00:02,  5.06it/s, loss=0.592, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:  48%|████▊     | 13/27 [00:02<00:02,  5.07it/s, loss=0.607, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  52%|█████▏    | 14/27 [00:02<00:02,  5.06it/s, loss=0.603, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  56%|█████▌    | 15/27 [00:02<00:02,  5.06it/s, loss=0.601, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  59%|█████▉    | 16/27 [00:03<00:02,  5.06it/s, loss=0.587, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  63%|██████▎   | 17/27 [00:03<00:01,  5.06it/s, loss=0.581, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  67%|██████▋   | 18/27 [00:03<00:01,  5.07it/s, loss=0.575, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  70%|███████   | 19/27 [00:03<00:01,  5.07it/s, loss=0.576, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  74%|███████▍  | 20/27 [00:03<00:01,  5.07it/s, loss=0.578, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  78%|███████▊  | 21/27 [00:04<00:01,  5.07it/s, loss=0.584, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  81%|████████▏ | 22/27 [00:04<00:00,  5.08it/s, loss=0.586, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 33:  85%|████████▌ | 23/27 [00:04<00:00,  5.09it/s, loss=0.576, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  89%|████████▉ | 24/27 [00:04<00:00,  5.09it/s, loss=0.568, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  93%|█████████▎| 25/27 [00:04<00:00,  5.10it/s, loss=0.57, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 33:  96%|█████████▋| 26/27 [00:05<00:00,  5.18it/s, loss=0.57, v_num=1, val_loss=0.542, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.575, train_ttr=0.000, train_ftr=0.000, train_acc=0.743]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.57, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]         forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:   4%|▎         | 1/27 [00:00<00:05,  5.04it/s, loss=0.574, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 34:   7%|▋         | 2/27 [00:00<00:04,  5.11it/s, loss=0.573, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  11%|█         | 3/27 [00:00<00:04,  5.13it/s, loss=0.57, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746] forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  15%|█▍        | 4/27 [00:00<00:04,  5.14it/s, loss=0.576, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  19%|█▊        | 5/27 [00:00<00:04,  5.15it/s, loss=0.585, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  22%|██▏       | 6/27 [00:01<00:04,  5.16it/s, loss=0.58, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  26%|██▌       | 7/27 [00:01<00:03,  5.14it/s, loss=0.589, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  30%|██▉       | 8/27 [00:01<00:03,  5.14it/s, loss=0.585, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  33%|███▎      | 9/27 [00:01<00:03,  5.15it/s, loss=0.582, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  37%|███▋      | 10/27 [00:01<00:03,  5.15it/s, loss=0.58, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746] forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 34:  41%|████      | 11/27 [00:02<00:03,  5.16it/s, loss=0.58, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 34:  44%|████▍     | 12/27 [00:02<00:02,  5.15it/s, loss=0.583, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 34:  48%|████▊     | 13/27 [00:02<00:02,  5.15it/s, loss=0.588, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  52%|█████▏    | 14/27 [00:02<00:02,  5.15it/s, loss=0.579, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 34:  56%|█████▌    | 15/27 [00:02<00:02,  5.15it/s, loss=0.573, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  59%|█████▉    | 16/27 [00:03<00:02,  5.16it/s, loss=0.563, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  63%|██████▎   | 17/27 [00:03<00:01,  5.16it/s, loss=0.555, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  67%|██████▋   | 18/27 [00:03<00:01,  5.15it/s, loss=0.561, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  70%|███████   | 19/27 [00:03<00:01,  5.15it/s, loss=0.566, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  74%|███████▍  | 20/27 [00:03<00:01,  5.15it/s, loss=0.565, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 34:  78%|███████▊  | 21/27 [00:04<00:01,  5.15it/s, loss=0.562, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 34:  81%|████████▏ | 22/27 [00:04<00:00,  5.15it/s, loss=0.568, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  85%|████████▌ | 23/27 [00:04<00:00,  5.15it/s, loss=0.572, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 34:  89%|████████▉ | 24/27 [00:04<00:00,  5.14it/s, loss=0.573, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 34:  93%|█████████▎| 25/27 [00:04<00:00,  5.14it/s, loss=0.571, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 34:  96%|█████████▋| 26/27 [00:04<00:00,  5.22it/s, loss=0.571, v_num=1, val_loss=0.535, val_ttr=0.000, val_ftr=0.000, val_acc=0.782, train_loss=0.579, train_ttr=0.000, train_ftr=0.000, train_acc=0.746]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:   0%|          | 0/27 [00:00<?, ?it/s, loss=0.571, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]         forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:   4%|▎         | 1/27 [00:00<00:07,  3.59it/s, loss=0.574, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:   7%|▋         | 2/27 [00:00<00:05,  4.28it/s, loss=0.568, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  11%|█         | 3/27 [00:00<00:05,  4.55it/s, loss=0.564, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  15%|█▍        | 4/27 [00:00<00:04,  4.68it/s, loss=0.564, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  19%|█▊        | 5/27 [00:01<00:04,  4.77it/s, loss=0.562, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  22%|██▏       | 6/27 [00:01<00:04,  4.82it/s, loss=0.572, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  26%|██▌       | 7/27 [00:01<00:04,  4.86it/s, loss=0.575, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  30%|██▉       | 8/27 [00:01<00:03,  4.88it/s, loss=0.573, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  33%|███▎      | 9/27 [00:01<00:03,  4.91it/s, loss=0.581, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  37%|███▋      | 10/27 [00:02<00:03,  4.92it/s, loss=0.586, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  41%|████      | 11/27 [00:02<00:03,  4.94it/s, loss=0.596, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  44%|████▍     | 12/27 [00:02<00:03,  4.96it/s, loss=0.597, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  48%|████▊     | 13/27 [00:02<00:02,  4.97it/s, loss=0.597, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  52%|█████▏    | 14/27 [00:02<00:02,  4.97it/s, loss=0.597, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  56%|█████▌    | 15/27 [00:03<00:02,  4.98it/s, loss=0.595, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  59%|█████▉    | 16/27 [00:03<00:02,  4.98it/s, loss=0.594, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  63%|██████▎   | 17/27 [00:03<00:02,  4.98it/s, loss=0.587, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  67%|██████▋   | 18/27 [00:03<00:01,  4.98it/s, loss=0.587, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  70%|███████   | 19/27 [00:03<00:01,  4.99it/s, loss=0.582, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  74%|███████▍  | 20/27 [00:03<00:01,  5.00it/s, loss=0.577, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  78%|███████▊  | 21/27 [00:04<00:01,  5.01it/s, loss=0.573, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  81%|████████▏ | 22/27 [00:04<00:00,  5.01it/s, loss=0.576, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  85%|████████▌ | 23/27 [00:04<00:00,  5.02it/s, loss=0.574, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35:  89%|████████▉ | 24/27 [00:04<00:00,  5.02it/s, loss=0.576, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  93%|█████████▎| 25/27 [00:04<00:00,  5.03it/s, loss=0.573, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Epoch 35:  96%|█████████▋| 26/27 [00:05<00:00,  5.11it/s, loss=0.573, v_num=1, val_loss=0.506, val_ttr=0.000, val_ftr=0.000, val_acc=0.797, train_loss=0.576, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Epoch 35: 100%|██████████| 27/27 [00:05<00:00,  5.16it/s, loss=0.573, v_num=1, val_loss=0.483, val_ttr=0.000, val_ftr=0.000, val_acc=0.814, train_loss=0.573, train_ttr=0.000, train_ftr=0.000, train_acc=0.744]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n",
      "Restoring states from the checkpoint path at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n",
      "Restoring states from the checkpoint path at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n",
      "Restoring states from the checkpoint path at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n",
      "Restoring states from the checkpoint path at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Loaded model weights from checkpoint at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n",
      "Loaded model weights from checkpoint at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n",
      "Loaded model weights from checkpoint at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n",
      "Loaded model weights from checkpoint at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n",
      "Loaded model weights from checkpoint at /home/akinwilson/Code/pytorch/output/model/HSTAT/epoch=10-val_loss=0.47-val_acc=0.83-val_ttr=0.00-val_ftr=0.00.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/3 [00:00<?, ?it/s]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Testing DataLoader 0:  33%|███▎      | 1/3 [00:00<00:00, 11.82it/s]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "Testing DataLoader 0:  67%|██████▋   | 2/3 [00:00<00:00, 10.39it/s]forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([11, 64, 768])\n",
      "forward_features[x, attn = layer(x)] [out]: torch.Size([10, 64, 768])\n",
      "forward_features[self.norm(x)] [out]: torch.Size([10, 64, 768])\n",
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  9.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7414141297340393     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_ftr          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_ttr          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7414141297340393    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_ftr         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_ttr         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_ttr': 0.0, 'test_ftr': 0.0, 'test_acc': 0.7414141297340393}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl \n",
    "import torch.nn.functional as F \n",
    "from wwv.architecture import ResNet, Predictor, Bottleneck\n",
    "from wwv.eval import Metric\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from wwv.util import OnnxExporter\n",
    "import bisect \n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint,LearningRateMonitor, ModelPruning\n",
    "from wwv.data import AudioDataModule\n",
    "import torch \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "data_path = DataPaths(cfg.path['data_dir'], cfg.model_name, cfg.path['model_dir'])\n",
    "\n",
    "cfg = Config(params)\n",
    "# model = Architecture(cfg, training=True)\n",
    "# model.extractor(torch.randn((1,48000))) # (torch.randn((1,48000)))\n",
    "# model = Architecture(cfg, True)\n",
    "data_module = AudioDataModule(data_path.root_data_dir + \"/train.csv\",\n",
    "                              data_path.root_data_dir + \"/val.csv\",\n",
    "                              data_path.root_data_dir + \"/test.csv\",\n",
    "                              cfg=cfg)\n",
    "                              \n",
    "train_loader =  data_module.train_dataloader()\n",
    "val_loader =  data_module.val_dataloader()\n",
    "test_loader =  data_module.test_dataloader()\n",
    "# model.processing_layer[3](x)\n",
    "\n",
    "\n",
    "class Routine(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model, cfg):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.metric = Metric\n",
    "        self.cfg = cfg\n",
    "        self.lr = 1e-3\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x = batch['x']\n",
    "        y = batch['y']\n",
    "        y_hat = self.model(x)\n",
    "        y_hat = y_hat.squeeze()\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_hat = (F.sigmoid(y_hat) > 0.5).float()\n",
    "\n",
    "        metrics = self.metric(y_hat, y, self.cfg)()\n",
    "        return {\"loss\":loss, \"train_ttr\": metrics.ttr, \"train_ftr\": metrics.ftr, \"train_acc\": metrics.acc}\n",
    "\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        results = {\n",
    "            \"loss\": torch.tensor([x['loss'].float().item() for x in training_step_outputs]).mean(),\n",
    "            \"ttr\": torch.tensor([x['train_ttr'].float().mean().item() for x in training_step_outputs]).mean(),\n",
    "            \"ftr\": torch.tensor([x['train_ftr'].float().mean().item() for x in training_step_outputs]).mean(),\n",
    "            \"acc\": torch.tensor([x['train_acc'].float().mean().item() for x in training_step_outputs]).mean()\n",
    "            }\n",
    "        # self.log(f\"LR\",self.lr, on_epoch=True, prog_bar=True, logger=True)\n",
    "        for (k,v) in results.items():\n",
    "            self.log(f\"train_{k}\", v, on_epoch=True, prog_bar=True, logger=True)    \n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch['x']\n",
    "        y = batch['y']\n",
    "        y_hat = self.model(x)\n",
    "        # (batch, num_classes)\n",
    "        y_hat = y_hat.squeeze()\n",
    "        # (batch,)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        pred = F.sigmoid(y_hat)\n",
    "        y_hat = (pred > 0.5).float()\n",
    "        metrics = self.metric(y_hat, y)()\n",
    "        return {\"val_loss\": loss, \"val_ttr\": metrics.ttr, \"val_ftr\": metrics.ftr, \"val_acc\": metrics.acc}\n",
    "\n",
    "\n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        results = {\n",
    "            \"loss\": torch.tensor([x['val_loss'].float().mean().item() for x in validation_step_outputs]).mean(),\n",
    "            \"ttr\": torch.tensor([x['val_ttr'].float().mean().item() for x in validation_step_outputs]).mean(),\n",
    "            \"ftr\": torch.tensor([x['val_ftr'].float().mean().item() for x in validation_step_outputs]).mean(),\n",
    "            \"acc\": torch.tensor([x['val_acc'].float().mean().item() for x in validation_step_outputs]).mean()\n",
    "            }\n",
    "        for (k,v) in results.items():\n",
    "            self.log(f\"val_{k}\", v, on_epoch=True, prog_bar=True, logger=True)    \n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = batch['x']\n",
    "        y = batch['y']\n",
    "        y_hat = self.model(x)\n",
    "        # (batch, num_classes)\n",
    "        y_hat = y_hat.squeeze()\n",
    "        # (batch,)\n",
    "        pred = F.sigmoid(y_hat)\n",
    "        # (batch_probabilities,)\n",
    "        y_hat = (pred > 0.5).float()\n",
    "        # (batch_labels,)\n",
    "        metrics = self.metric(y_hat, y)()\n",
    "        return {\"test_ttr\": metrics.ttr, \"test_ftr\": metrics.ftr, \"test_acc\": metrics.acc}\n",
    "\n",
    "\n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        results = {\n",
    "            \"ttr\": torch.tensor([x['test_ttr'].float().mean().item() for x in test_step_outputs]).mean(),\n",
    "            \"ftr\": torch.tensor([x['test_ftr'].float().mean().item() for x in test_step_outputs]).mean(),\n",
    "            \"acc\": torch.tensor([x['test_acc'].float().mean().item() for x in test_step_outputs]).mean()\n",
    "            }\n",
    "\n",
    "        for (k,v) in results.items():\n",
    "            self.log(f\"test_{k}\", v, on_epoch=True, prog_bar=True, logger=True)    \n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        # optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, self.parameters()),\n",
    "            lr = self.lr, \n",
    "            betas = (0.9, 0.999), eps = 1e-08, weight_decay = 0.05, \n",
    "        )\n",
    "\n",
    "        # scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
    "\n",
    "        def lr_warm_up(epoch):\n",
    "            if epoch < 3:\n",
    "                # warm up lr\n",
    "                lr_scale = self.cfg.lr_rates[epoch]\n",
    "            else:\n",
    "                # warmup schedule\n",
    "                lr_pos = int(-1 - bisect.bisect_left(self.cfg.lr_scheduler_epoch, epoch))\n",
    "                if lr_pos < -3:\n",
    "                    lr_scale = max(self.cfg.lr_rates[0] * (0.98 ** epoch), 0.03 )\n",
    "                else:\n",
    "                    lr_scale = self.cfg.lr_rates[lr_pos]\n",
    "            return lr_scale\n",
    "\n",
    "\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lr_warm_up\n",
    "        )\n",
    "        \n",
    "        return  {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"} \n",
    "\n",
    "\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "early_stopping = EarlyStopping(mode=\"min\", monitor='val_loss', patience=25)\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\",\n",
    "                                        dirpath=data_path.model_dir,\n",
    "                                        save_top_k=1,\n",
    "                                        mode=\"min\",\n",
    "                                        filename='{epoch}-{val_loss:.2f}-{val_acc:.2f}-{val_ttr:.2f}-{val_ftr:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # model = ResNet(block=Bottleneck, num_blocks=[8, 8, 36, 3], cfg=cfg)\n",
    "# model = DeepSpeech(40)\n",
    "\n",
    "config = HTSATConfig()\n",
    "\n",
    "model = HTSAT_Swin_Transformer(\n",
    "    spec_size=config.htsat_spec_size,\n",
    "    patch_size=config.htsat_patch_size,\n",
    "    in_chans=1,\n",
    "    num_classes=config.classes_num,\n",
    "    window_size=config.htsat_window_size,\n",
    "    config = config,\n",
    "    depths = config.htsat_depth,\n",
    "    embed_dim = config.htsat_dim,\n",
    "    patch_stride=config.htsat_stride,\n",
    "    num_heads=config.htsat_num_head\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint_callback, lr_monitor, early_stopping]\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=data_path.model_dir, version=1, name=\"lightning_logs\")\n",
    "\n",
    "trainer = Trainer(accelerator=\"gpu\",\n",
    "                  devices=3,\n",
    "                  strategy='dp',\n",
    "                  logger = logger, \n",
    "                  default_root_dir=data_path.model_dir,\n",
    "                  callbacks=callbacks)\n",
    "trainer.fit(Routine(model, cfg), train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "trainer.test(dataloaders=test_loader)\n",
    "\n",
    "\n",
    "# from wwv.util import OnnxExporter\n",
    "# model = trainer.model.module.module.model\n",
    "# predictor = Predictor(model)\n",
    "# OnnxExporter( model=predictor,\n",
    "#              cfg=cfg, \n",
    "#              output_dir=data_path.model_dir)()\n",
    "\n",
    "#####################################################################################################################\n",
    "#                                            \n",
    "#####################################################################################################################\n",
    "# if isinstance(trainer.model, torch.nn.DataParallel):\n",
    "#     print(\"test\")\n",
    "#     model = trainer.model\n",
    "#####################################################################################################################\n",
    "# reload best \n",
    "#####################################################################################################################\n",
    "# automatically auto-loads the best weights from the previous run \n",
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FullyConnected(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n_feature: Number of input features\n",
    "        n_hidden: Internal hidden unit size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_feature: int, n_hidden: int, dropout: float, relu_max_clip: int = 20) -> None:\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.fc = torch.nn.Linear(n_feature, n_hidden, bias=True)\n",
    "        self.relu_max_clip = relu_max_clip\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.fc(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.hardtanh(x, 0, self.relu_max_clip)\n",
    "        if self.dropout:\n",
    "            x = torch.nn.functional.dropout(x, self.dropout, self.training)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeepSpeech(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    DeepSpeech model architecture from *Deep Speech: Scaling up end-to-end speech recognition*\n",
    "    [:footcite:`hannun2014deep`].\n",
    "\n",
    "    Args:\n",
    "        n_feature: Number of input features\n",
    "        n_hidden: Internal hidden unit size.\n",
    "        n_class: Number of output classes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_feature: int=40,\n",
    "        n_hidden: int = 4024,\n",
    "        n_class: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.fc1 = FullyConnected(n_feature, n_hidden, dropout)\n",
    "        self.fc2 = FullyConnected(n_hidden, n_hidden, dropout)\n",
    "        self.fc3 = FullyConnected(n_hidden, n_hidden, dropout)\n",
    "        self.bi_rnn = torch.nn.RNN(n_hidden, n_hidden, num_layers=1, nonlinearity=\"relu\", bidirectional=True)\n",
    "        self.fc4 = FullyConnected(n_hidden, n_hidden, dropout)\n",
    "        # self.flat = torch.nn.Flatten()\n",
    "\n",
    "        self.out = torch.nn.Linear(241*n_hidden, n_class)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Tensor of dimension (batch, channel, time, feature).\n",
    "        Returns:\n",
    "            Tensor: Predictor tensor of dimension (batch, time, class).\n",
    "        \"\"\"\n",
    "# 241, 512\n",
    "        # n_mfcc:40, timstep:241 (1,40, 241)\n",
    "        # N x C x F x T \n",
    "        x = x.transpose(2,3)\n",
    "        # N x C x T x F\n",
    "        x = self.fc1(x)\n",
    "        # N x C x T x H\n",
    "        x = self.fc2(x)\n",
    "        # N x C x T x H\n",
    "        x = self.fc3(x)\n",
    "        # N x C x T x H\n",
    "        x = x.squeeze(1)\n",
    "        # N x T x H\n",
    "        x = x.transpose(0, 1)\n",
    "        # T x N x H\n",
    "        x, _ = self.bi_rnn(x)\n",
    "        # The fifth (non-recurrent) layer takes both the forward and backward units as inputs\n",
    "        x = x[:, :, : self.n_hidden] + x[:, :, self.n_hidden :]\n",
    "        # T x N x H\n",
    "        x = self.fc4(x)\n",
    "        # T x N x H\n",
    "        x = x.permute(1, 0, 2)\n",
    "        # N x T x n_class\n",
    "        # print(f\"x = x.permute(1, 0, 2) {x.shape}\")\n",
    "        # print(f\"{}\")\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # print(f\"x = x.reshape(x.shape[0], -1) {x.shape}\")\n",
    "        # N x (T x n_class)\n",
    "        x = self.out(x)\n",
    "        # N x n_class\n",
    "        return x\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=1, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print(f\"x = self.conv1(x) {self.conv1(x)}\") \n",
    "        \n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "x = torch.randn((1,48000))\n",
    "M5()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessingLayer(nn.Module):\n",
    "\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.cfg =cfg\n",
    "        layers = []\n",
    "        kwargs = cfg.audio_feature_param[cfg.audio_feature]\n",
    "        if cfg.audio_feature == \"spectrogram\":\n",
    "            layers.append(features.MelSpectrogram(**kwargs))\n",
    "            # layers.append(T.Resize(224)) # size expected by 2D ResNet \n",
    "        elif cfg.audio_feature == \"mfcc\":\n",
    "            layers.append(features.MFCC(**kwargs))\n",
    "            # layers.append(T.Resize(224)) # size expected by 2D ResNet\n",
    "\n",
    "        # resize inputs\n",
    "        # layers.append(transforms.RandomResizedCrop(224))\n",
    "        self.net = torch.nn.Sequential(*layers)\n",
    "        # logger.info(f\"{'-'*20}> Features to be extracted: {cfg.audio_feature}\")\n",
    "        # logger.info(f\"{'-'*20}> Feature dimensions: {cfg.processing_output_shape}\")\n",
    "\n",
    "    def forward(self, x:torch.tensor) -> torch.tensor:\n",
    "        x_out = self.net(x)\n",
    "        # if self.cfg.verbose:\n",
    "        #     logger.info(f\"ProcessingLayer().foward() [in]: {x.shape}\")\n",
    "        #     logger.info(f\"ProcessingLayer().foward() [out]: {x_out.shape}\")\n",
    "        return x_out \n",
    "\n",
    "\n",
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "\n",
    "    def __init__(self, n_feats):\n",
    "        super().__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous()  # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous()  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "    except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x  # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super().__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=batch_first,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "from math import prod\n",
    "\n",
    "class DeepSpeech(nn.Module):\n",
    "\n",
    "    def __init__(self, n_cnn_layers=20, n_rnn_layers=1, rnn_dim=1096, stride=2, dropout=0.1,cfg=cfg, **kwargs):\n",
    "        super().__init__()\n",
    "        self.cfg= cfg \n",
    "        #  =n_mfcc:40, timstep () 40, 241\n",
    "        \n",
    "        def ceildiv(a, b):\n",
    "            return -(a // -b)\n",
    "\n",
    "        in_feat_dim = (121//2, 20//2) #  self.cfg.processing_output_shape\n",
    "        # self.processing_layer = ProcessingLayer(cfg)\n",
    "        # n_feats =  (121 * 20) // 2\n",
    "    \n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3 // 2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(\n",
    "            *[ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=in_feat_dim) for _ in range(n_cnn_layers)]\n",
    "        )\n",
    "        \n",
    "        self.fully_connected = nn.Linear(121, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(\n",
    "            *[\n",
    "                BidirectionalGRU(\n",
    "                    rnn_dim=rnn_dim if i == 0 else rnn_dim * 2,\n",
    "                    hidden_size=rnn_dim,\n",
    "                    dropout=dropout,\n",
    "                    batch_first=i == 0,\n",
    "                )\n",
    "                for i in range(n_rnn_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1402880, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Shape b cnn {x.shape}\")\n",
    "        # x = self.processing_layer(x) # (batch, mfcc, timestep)\n",
    "        # print(f\"Shape a process {x.shape}\")\n",
    "        # x = x.unsqueeze(1) # (batch, channel,  mfcc, timestep)\n",
    "        # print(f\"Shape a transpose {x.shape}\")\n",
    "        x = self.cnn(x)\n",
    "        print(f\"Shape a cnn {x.shape}\")\n",
    "        x = self.rescnn_layers(x)\n",
    "        print(f\"Shape a rescnn {x.shape}\")\n",
    "        \n",
    "        # # print(f\"after view {x.shape}\")\n",
    "        # x = x.transpose(1, 2)  # (batch, time, feature)\n",
    "\n",
    "        x = self.fully_connected(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        print(f\"Shape a fully_connected {x.shape}\")\n",
    "        x = self.birnn_layers(x)\n",
    "        print(f\"Shape a birnn_layers {x.shape}\")\n",
    "        # print(f\"after birnn_layers {x.shape}\")\n",
    "        x =  self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "n_feats = (1,121, 20) #  self.cfg.processing_output_shape\n",
    "# self.processing_layer = ProcessingLayer(cfg)\n",
    "# n_feats =  (121 * 20) // 2\n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "    except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel // 2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x  # (batch, channel, feature, time)\n",
    "\n",
    "xin = torch.randn(n_feats)\n",
    "stride=2\n",
    "cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3 // 2)\n",
    "# (61, 10)\n",
    "def ceildiv(a, b):\n",
    "    return -(a // -b)\n",
    "\n",
    "n_feats = (ceildiv(121,2), ceildiv(20,2) )\n",
    "\n",
    "\n",
    "print(n_feats)\n",
    "rescnn_layers = nn.Sequential(\n",
    "            *[ResidualCNN(32, 32, kernel=3, stride=1, dropout=0.1, n_feats=n_feats) for _ in range(2)]\n",
    "        )\n",
    "        \n",
    "# .shape\n",
    "\n",
    "rescnn_layers(cnn(xin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, SEWDForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "# dataset = dataset.sort(\"id\")\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "class SEW(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"anton-l/sew-d-mid-400k-ft-keyword-spotting\")\n",
    "        self.model = SEWDForSequenceClassification.from_pretrained(\"anton-l/sew-d-mid-400k-ft-keyword-spotting\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = input_dict['input_values']\n",
    "        x_feats = self.feature_extractor(x, ampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "        x_feats.unsqueeze(1)\n",
    "        logits = self.model(x)\n",
    "        return logits \n",
    "\n",
    "dataset[0][\"audio\"][\"array\"]\n",
    "sew  =SEW()\n",
    "# # audio file is decoded on the fly\n",
    "\n",
    "inputs = dataset[0][\"audio\"][\"array\"]\n",
    "with torch.no_grad():\n",
    "    logits = sew(torch.tensor(inputs))\n",
    "print(logits)\n",
    "# predicted_class_ids = torch.argmax(logits, dim=-1).item()\n",
    "# predicted_label = model.config.id2label[predicted_class_ids]\n",
    "# predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "# Run learning rate finder\n",
    "model = ResNet(block=Bottleneck, num_blocks=[3, 8, 36, 3], cfg=cfg)\n",
    "model = Routine(model, cfg)\n",
    "\n",
    "lr_finder = trainer.tuner.lr_find(model)\n",
    "\n",
    "# Results can be found in\n",
    "lr_finder.results\n",
    "\n",
    "# Plot with\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()\n",
    "\n",
    "# Pick point based on plot, or get suggestion\n",
    "# new_lr = lr_finder.suggestion()\n",
    "\n",
    "# # update hparams of the model\n",
    "# model.hparams.lr = new_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TensorRT \n",
    "rt = {\n",
    "  \"error\": False,\n",
    "  \"result\": {\n",
    "    \"wake_word_probability\": 0,\n",
    "    \"prediction\": 0,\n",
    "    \"false_alarm_probability\": 1,\n",
    "    \"decision_threshold\": 0.5,\n",
    "    \"wwvm_version\": \"docker-env-model-version\",\n",
    "    \"inference_time\": 0.01810431480407715\n",
    "  }\n",
    "}\n",
    "\n",
    "# with CPU\n",
    "cpu = {\n",
    "  \"error\": False,\n",
    "  \"result\": {\n",
    "    \"wake_word_probability\": 0,\n",
    "    \"prediction\": 0,\n",
    "    \"false_alarm_probability\": 1,\n",
    "    \"decision_threshold\": 0.5,\n",
    "    \"wwvm_version\": \"docker-env-model-version\",\n",
    "    \"inference_time\": 0.08728623390197754\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# with cuda \n",
    "cuda = {\n",
    "  \"error\": False,\n",
    "  \"result\": {\n",
    "    \"wake_word_probability\": 0,\n",
    "    \"prediction\": 0,\n",
    "    \"false_alarm_probability\": 1,\n",
    "    \"decision_threshold\": 0.5,\n",
    "    \"wwvm_version\": \"docker-env-model-version\",\n",
    "    \"inference_time\": 0.022240400314331055\n",
    "  }\n",
    "}\n",
    "\n",
    "def get_factor(d1,d2):\n",
    "  return d1['result']['inference_time'] / d2['result']['inference_time']\n",
    "\n",
    "\n",
    "print(f\"Cuda {get_factor(cpu,cuda):.2f} faster than cpu\")\n",
    "print(f\"TensorRT {get_factor(cpu,rt):.2f} faster than cpu\")\n",
    "print(f\"TensorRT {get_factor(cuda,rt):.2f} faster than cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch \n",
    "# PATH = \"/home/akinwilson/Code/pytorch/output/model/epoch=27-val_loss=0.16-val_acc=0.97.ckpt\"\n",
    "# model.load_state_dict(torch.load(PATH), map_location=torch.device('cpu'))\n",
    "# trainer.test(test_loader, ckpt_path='best')\n",
    "from torch import tensor \n",
    "# ftrs = [x['train_ftr'].mean().item() for x in training_step_outputs]\n",
    "# accs = [x['train_acc'].mean().item() for x in training_step_outputs]\n",
    "# losses\n",
    "# ttrs\n",
    "# results = {\"avg_loss\": statistics.fmean([x['loss'].item() for x in training_step_outputs]),}\n",
    "            # \"avg_ttr\": torch.stack([x['train_ttr'].mean().item() for x in training_step_outputs]).mean(),\n",
    "            # \"avg_ftr\": torch.stack([x['train_ftr'].mean().item() for x in training_step_outputs]).mean(),\n",
    "            # \"avg_acc\": torch.stack([x['train_acc'].mean().item() for x in training_step_outputs]).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class dataset(Dataset):\n",
    "  def __init__(self,x,y):\n",
    "    self.x = torch.tensor(x,dtype=torch.float32)\n",
    "    self.y = torch.tensor(y,dtype=torch.float32)\n",
    "    self.length = self.x.shape[0]\n",
    " \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x[idx],self.y[idx]\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "\n",
    "xs =torch.ones(64, 48000)\n",
    "ys = torch.ones(64)\n",
    "\n",
    "trainset = dataset(xs,ys)\n",
    "#DataLoader\n",
    "trainloader = DataLoader(trainset,batch_size=64,shuffle=False)\n",
    "for b in trainloader:\n",
    "  print(b[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-T3BHxh3q",
   "language": "python",
   "name": "pytorch-t3bhxh3q"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
