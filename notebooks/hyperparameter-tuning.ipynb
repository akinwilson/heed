{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading env vars from file: ./env_vars/resnet/.dev.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-06 02:43:56,069] A new study created in memory with name: no-name-db2eb44c-bfa4-4f19-bb85-959dfd74188b\n",
      "[W 2023-07-06 02:43:57,637] Trial 0 failed with parameters: {'dropout': 0.2371586889725183} because of the following error: MisconfigurationException('You requested gpu: [0, 1, 2, 3]\\n But your machine only has: [0]').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/otis/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_1910700/4279677413.py\", line 167, in objective\n",
      "    trainer = Trainer(\n",
      "  File \"/home/otis/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py\", line 69, in insert_env_defaults\n",
      "    return fn(self, **kwargs)\n",
      "  File \"/home/otis/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 398, in __init__\n",
      "    self._accelerator_connector = _AcceleratorConnector(\n",
      "  File \"/home/otis/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\", line 157, in __init__\n",
      "    self._set_parallel_devices_and_init_accelerator()\n",
      "  File \"/home/otis/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py\", line 389, in _set_parallel_devices_and_init_accelerator\n",
      "    self._devices_flag = accelerator_cls.parse_devices(self._devices_flag)\n",
      "  File \"/home/otis/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/accelerators/cuda.py\", line 81, in parse_devices\n",
      "    return _parse_gpu_ids(devices, include_cuda=True)\n",
      "  File \"/home/otis/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/lightning_fabric/utilities/device_parser.py\", line 102, in _parse_gpu_ids\n",
      "    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)\n",
      "  File \"/home/otis/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/lightning_fabric/utilities/device_parser.py\", line 134, in _sanitize_gpu_ids\n",
      "    raise MisconfigurationException(\n",
      "lightning_fabric.utilities.exceptions.MisconfigurationException: You requested gpu: [0, 1, 2, 3]\n",
      " But your machine only has: [0]\n",
      "[W 2023-07-06 02:43:57,644] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "You requested gpu: [0, 1, 2, 3]\n But your machine only has: [0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb Cell 2\u001b[0m in \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=191'>192</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39moptuna\u001b[39;00m \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=194'>195</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     _optimize(\n\u001b[1;32m    443\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    444\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    445\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    446\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    447\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    448\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    449\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    450\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    451\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    452\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb Cell 2\u001b[0m in \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m routine \u001b[39m=\u001b[39m Routine(model, cfg_fitting, cfg_model)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m callbacks \u001b[39m=\u001b[39m get_callbacks() \u001b[39m+\u001b[39m [PyTorchLightningPruningCallback(trial, monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m     accelerator\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=168'>169</a>\u001b[0m     devices\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(number_devices),\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m     strategy\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mgetenv(\u001b[39m\"\u001b[39;49m\u001b[39mSTRATEGY\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mddp\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=171'>172</a>\u001b[0m     max_epochs\u001b[39m=\u001b[39;49mcfg_fitting\u001b[39m.\u001b[39;49mmax_epoch,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=172'>173</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=173'>174</a>\u001b[0m     num_sanity_val_steps\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=174'>175</a>\u001b[0m     \u001b[39m# resume_from_checkpoint=self.cfg_fitting.resume_from_checkpoint,\u001b[39;49;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m     gradient_clip_val\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m     fast_dev_run\u001b[39m=\u001b[39;49mcfg_fitting\u001b[39m.\u001b[39;49mfast_dev_run,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=177'>178</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m hyperparameters \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(dropout\u001b[39m=\u001b[39mdropout)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/otis/Code/DL-torch-audio/notebooks/hyperparameter-tuning.ipynb#W1sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m trainer\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mlog_hyperparams(hyperparameters)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/utilities/argparse.py:69\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mlist\u001b[39m(env_variables\u001b[39m.\u001b[39mitems()) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mitems()))\n\u001b[1;32m     68\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:398\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39m# init connectors\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector \u001b[39m=\u001b[39m _DataConnector(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_connector \u001b[39m=\u001b[39m _AcceleratorConnector(\n\u001b[1;32m    399\u001b[0m     devices\u001b[39m=\u001b[39;49mdevices,\n\u001b[1;32m    400\u001b[0m     accelerator\u001b[39m=\u001b[39;49maccelerator,\n\u001b[1;32m    401\u001b[0m     strategy\u001b[39m=\u001b[39;49mstrategy,\n\u001b[1;32m    402\u001b[0m     num_nodes\u001b[39m=\u001b[39;49mnum_nodes,\n\u001b[1;32m    403\u001b[0m     sync_batchnorm\u001b[39m=\u001b[39;49msync_batchnorm,\n\u001b[1;32m    404\u001b[0m     benchmark\u001b[39m=\u001b[39;49mbenchmark,\n\u001b[1;32m    405\u001b[0m     use_distributed_sampler\u001b[39m=\u001b[39;49muse_distributed_sampler,\n\u001b[1;32m    406\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m    407\u001b[0m     precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[1;32m    408\u001b[0m     plugins\u001b[39m=\u001b[39;49mplugins,\n\u001b[1;32m    409\u001b[0m )\n\u001b[1;32m    410\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector \u001b[39m=\u001b[39m _LoggerConnector(\u001b[39mself\u001b[39m)\n\u001b[1;32m    411\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback_connector \u001b[39m=\u001b[39m _CallbackConnector(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:157\u001b[0m, in \u001b[0;36m_AcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerator_flag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_gpu_accelerator_backend()\n\u001b[1;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_device_config_and_set_final_flags(devices\u001b[39m=\u001b[39mdevices, num_nodes\u001b[39m=\u001b[39mnum_nodes)\n\u001b[0;32m--> 157\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_parallel_devices_and_init_accelerator()\n\u001b[1;32m    159\u001b[0m \u001b[39m# 3. Instantiate ClusterEnvironment\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcluster_environment: ClusterEnvironment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_choose_and_init_cluster_environment()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:389\u001b[0m, in \u001b[0;36m_AcceleratorConnector._set_parallel_devices_and_init_accelerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    382\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00maccelerator_cls\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` can not run on your system\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m since the accelerator is not available. The following accelerator(s)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is available and can be passed into `accelerator` argument of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `Trainer`: \u001b[39m\u001b[39m{\u001b[39;00mavailable_accelerator\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m     )\n\u001b[1;32m    388\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_devices_flag_if_auto_passed()\n\u001b[0;32m--> 389\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_devices_flag \u001b[39m=\u001b[39m accelerator_cls\u001b[39m.\u001b[39;49mparse_devices(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_devices_flag)\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parallel_devices:\n\u001b[1;32m    391\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parallel_devices \u001b[39m=\u001b[39m accelerator_cls\u001b[39m.\u001b[39mget_parallel_devices(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_devices_flag)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/pytorch_lightning/accelerators/cuda.py:81\u001b[0m, in \u001b[0;36mCUDAAccelerator.parse_devices\u001b[0;34m(devices)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_devices\u001b[39m(devices: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m, List[\u001b[39mint\u001b[39m]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[List[\u001b[39mint\u001b[39m]]:\n\u001b[1;32m     80\u001b[0m     \u001b[39m\"\"\"Accelerator device parsing logic.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mreturn\u001b[39;00m _parse_gpu_ids(devices, include_cuda\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/lightning_fabric/utilities/device_parser.py:102\u001b[0m, in \u001b[0;36m_parse_gpu_ids\u001b[0;34m(gpus, include_cuda, include_mps)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m# Check that GPUs are unique. Duplicate GPUs are not supported by the backend.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m _check_unique(gpus)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m _sanitize_gpu_ids(gpus, include_cuda\u001b[39m=\u001b[39;49minclude_cuda, include_mps\u001b[39m=\u001b[39;49minclude_mps)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/DL-torch-audio-sllXh0tU/lib/python3.10/site-packages/lightning_fabric/utilities/device_parser.py:134\u001b[0m, in \u001b[0;36m_sanitize_gpu_ids\u001b[0;34m(gpus, include_cuda, include_mps)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mfor\u001b[39;00m gpu \u001b[39min\u001b[39;00m gpus:\n\u001b[1;32m    133\u001b[0m     \u001b[39mif\u001b[39;00m gpu \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m all_available_gpus:\n\u001b[0;32m--> 134\u001b[0m         \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    135\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou requested gpu: \u001b[39m\u001b[39m{\u001b[39;00mgpus\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m But your machine only has: \u001b[39m\u001b[39m{\u001b[39;00mall_available_gpus\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m         )\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m gpus\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: You requested gpu: [0, 1, 2, 3]\n But your machine only has: [0]"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "import os \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "from wwv.Architecture.ResNet.model import ResNet\n",
    "from wwv.routine import Routine \n",
    "from wwv.eval import Metric\n",
    "from wwv.util import OnnxExporter\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "from wwv.eval import Metric\n",
    "import statistics\n",
    "from wwv.data import AudioDataModule\n",
    "import wwv.config as cfg\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "\n",
    "import bisect \n",
    "import torch \n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl \n",
    "import torch.nn.functional as F \n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping,ModelCheckpoint,LearningRateMonitor, ModelPruning\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from wwv.util import get_username\n",
    "from wwv.Architecture.ResNet.model import ResNet\n",
    "from wwv.Architecture.HTSwin.model import HTSwinTransformer\n",
    "from wwv.Architecture.DeepSpeech.model import DeepSpeech\n",
    "from wwv.Architecture.LeeNet.model import LeeNet\n",
    "from wwv.Architecture.MobileNet.model import MobileNet\n",
    "\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    LearningRateMonitor,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "model_name = \"ResNet\"\n",
    "\n",
    "STR_TO_MODEL_CFGS = {\n",
    "    \"HSTAT\": cfg.HTSwin(),\n",
    "    \"ResNet\": cfg.ResNet(),\n",
    "    \"DeepSpeech\": cfg.DeepSpeech(),\n",
    "    \"LeeNet\": cfg.LeeNet(),\n",
    "    \"MobileNet\": cfg.MobileNet(),\n",
    "}\n",
    "STR_TO_MODELS = {\n",
    "    \"HSTAT\": HTSwinTransformer,\n",
    "    \"ResNet\": ResNet,\n",
    "    \"DeepSpeech\": DeepSpeech,\n",
    "    \"LeeNet\": LeeNet,\n",
    "    \"MobileNet\": MobileNet,\n",
    "}\n",
    "\n",
    "\n",
    "cfg_model = STR_TO_MODEL_CFGS[model_name]\n",
    "# select comp graph/model arch\n",
    "model = STR_TO_MODELS[model_name]\n",
    "\n",
    "\n",
    "\n",
    "env_filepath = os.getenv(\n",
    "    \"ENV_FILE_PATH\", f\"../env_vars/{model_name.lower()}/.dev.env\"\n",
    ")\n",
    "\n",
    "print(f\"Loading env vars from file: {env_filepath}\")\n",
    "load_dotenv(env_filepath)\n",
    "\n",
    "\n",
    "\n",
    "# init the fitter <---- associated  data loaders and fitting routine to model\n",
    "\n",
    "model = model\n",
    "cfg_model = cfg_model\n",
    "cfg_fitting = cfg.Fitting()\n",
    "cfg_signal = cfg.Signal()\n",
    "cfg_feature = cfg.Feature()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_path = cfg.DataPath(\n",
    "    f\"/media/{get_username()}/Samsung_T5/data/audio/keyword-spotting\", cfg_model.model_name, cfg_model.model_dir\n",
    ")\n",
    "\n",
    "def setup():\n",
    "    '''\n",
    "    Set up data module and loaders\n",
    "    '''\n",
    "    data_module = AudioDataModule(\n",
    "        data_path.root_data_dir,\n",
    "        cfg_model=cfg_model,\n",
    "        cfg_feature=cfg_feature,\n",
    "        cfg_fitting=cfg_fitting,\n",
    "    )\n",
    "\n",
    "    train_loader = data_module.train_dataloader()\n",
    "    val_loader = data_module.val_dataloader()\n",
    "    test_loader = data_module.test_dataloader()\n",
    "\n",
    "    return data_module, train_loader, val_loader, test_loader\n",
    "\n",
    "# get loaders and datamodule to access input shape\n",
    "data_module, train_loader, val_loader, test_loader = setup()\n",
    "\n",
    "# get input shape for onnx exporting\n",
    "input_shape = data_module.input_shape\n",
    "# init model\n",
    "\n",
    "# Init a trainer to execute routineSTR_TO_MODELS\n",
    "from wwv.util import OnnxExporter, CallbackCollection\n",
    "\n",
    "\n",
    "\n",
    "# callback_dict = callbacks()\n",
    "# callback_list = [v for (_, v) in callback_dict.items()]\n",
    "number_devices = os.getenv(\"CUDA_VISIBLE_DEVICES\", \"1,\").split(\",\")\n",
    "try:\n",
    "    number_devices.remove(\"\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_callbacks():\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "    early_stopping = EarlyStopping(mode=\"min\", monitor='val_loss', patience=cfg_fitting.es_patience)\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\",\n",
    "                                            dirpath=data_path.model_dir,\n",
    "                                            save_top_k=1,\n",
    "                                            mode=\"min\",\n",
    "                                            filename='{epoch}-{val_loss:.2f}-{val_acc:.2f}-{val_ttr:.2f}-{val_ftr:.2f}')\n",
    "    callbacks = [checkpoint_callback, lr_monitor, early_stopping]\n",
    "    return callbacks \n",
    "\n",
    "# def callbacks():\n",
    "#     cfg_fitting =cfg_fitting\n",
    "#     data_path = data_path\n",
    "#     callback_collection = CallbackCollection(cfg_fitting, data_path)\n",
    "#     return callback_collection()\n",
    "\n",
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "\n",
    "    # We optimize the number of layers, hidden units in each layer and dropouts.\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.2, 0.5)\n",
    "\n",
    "    Model = STR_TO_MODELS[model_name]\n",
    "    kwargs = {\n",
    "    \"num_blocks\": cfg_model.num_blocks,\n",
    "    \"dropout\": cfg_model.dropout,\n",
    "}\n",
    "    kwargs['dropout'] = dropout\n",
    "\n",
    "    model = Model(**kwargs)\n",
    "    # setup training, validating and testing routines for the model\n",
    "    routine = Routine(model, cfg_fitting, cfg_model)\n",
    "    callbacks = get_callbacks() + [PyTorchLightningPruningCallback(trial, monitor=\"val_acc\")]\n",
    "\n",
    "    trainer = Trainer(\n",
    "        accelerator=\"gpu\",\n",
    "        devices=len(number_devices),\n",
    "        strategy=os.getenv(\"STRATEGY\", \"ddp\"),\n",
    "        sync_batchnorm=True,\n",
    "        max_epochs=cfg_fitting.max_epoch,\n",
    "        callbacks=callbacks,\n",
    "        num_sanity_val_steps=2,\n",
    "        # resume_from_checkpoint=self.cfg_fitting.resume_from_checkpoint,\n",
    "        gradient_clip_val=1.0,\n",
    "        fast_dev_run=cfg_fitting.fast_dev_run,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    hyperparameters = dict(dropout=dropout)\n",
    "    trainer.logger.log_hyperparams(hyperparameters)\n",
    "    trainer.fit(\n",
    "        routine, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    "    )  # ,ckpt_path=PATH)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_acc\"].item()\n",
    "\n",
    "\n",
    "# trainer.test(dataloaders=test_loader)\n",
    "import optuna \n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "parser = ArgumentParser(description=\"PyTorch Lightning example.\")\n",
    "parser.add_argument(\n",
    "    \"--pruning\",\n",
    "    \"-p\",\n",
    "    action=\"store_true\",\n",
    "    help=\"Activate the pruning feature. `MedianPruner` stops unpromising \"\n",
    "    \"trials at the early stages of training.\",\n",
    ")\n",
    "args = parser.parse_args()\n",
    "\n",
    "pruner = optuna.pruners.BasePruner = optuna.pruners.MedianPruner()\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-torch-audio-sllXh0tU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
